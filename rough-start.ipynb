{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c559b678",
   "metadata": {},
   "source": [
    "Basic template for using untrained Whisper to detect singular curse words in a music track. Demucs is used to split the audio first then the vocals tracks is muted during the curse words. \n",
    "\n",
    "Probably everything should be done with .wav files to preserve audio integrity. There's also a lot of temp files that get created that could be deleted at the end (the separated tracks)\n",
    "\n",
    "Needed packages:\n",
    "- Whisper (audio-to-text, incl. pytorch, torchaudio)\n",
    "- Demucs (vocals stem separation)\n",
    "- pandas\n",
    "- os (file path management)\n",
    "- ffmpeg (for mp3)\n",
    "- soundfile (for wav)\n",
    "- pydub (for editing audio files)\n",
    "- mutagen (for preserving metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14df4a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Check for cuda/cpu\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device}')\n",
    "\n",
    "#### Load the model. I've tired the following:\n",
    "\n",
    "# large-v3-turbo (seems to perform the best?)\n",
    "# large-v3\n",
    "# medium.en (english only)\n",
    "# large (needs 10GB of VRAM and takes FOREVER)\n",
    "whisper_type = \"large-v3-turbo\"\n",
    "model = whisper.load_model(whisper_type, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aced78",
   "metadata": {},
   "source": [
    "Get file location and audio path, split into vocals and instruments. Demucs does a bunch of things automatically perhaps we can investigate further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2c55779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import demucs.separate\n",
    "import os\n",
    "\n",
    "# I put a few tracks in here\n",
    "song = 'jpeg'\n",
    "audio_file = f\"music/{song}.mp3\"\n",
    "\n",
    "# Format file path\n",
    "notebook_dir = os.getcwd()\n",
    "full_audio_path = os.path.join(notebook_dir, audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "802afae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model is a bag of 4 models. You will see that many progress bars per track.\n",
      "Separated tracks will be stored in C:\\Users\\dacla\\Documents\\auto-censoring-local\\separated\\mdx_extra\n",
      "Separating track c:\\Users\\dacla\\Documents\\auto-censoring-local\\music\\jpeg.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 132.0/132.0 [00:01<00:00, 117.74seconds/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 132.0/132.0 [00:01<00:00, 118.26seconds/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 132.0/132.0 [00:01<00:00, 119.33seconds/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 132.0/132.0 [00:01<00:00, 120.28seconds/s]\n"
     ]
    }
   ],
   "source": [
    "# Split the vocals with demucs\n",
    "demucs.separate.main([\"--two-stems\", \"vocals\", \"-n\", \"mdx_extra\", full_audio_path])\n",
    "\n",
    "# Comments:\n",
    "# Add \"--mp3\" command for output in mp3 format. But .wav is lossless and will probably (?) sound better\n",
    "# listening with headphones the audio processed with --mp3 sounded pretty weird\n",
    "# mdx_extra is just one of the models included in demucs. try other models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06484b1d",
   "metadata": {},
   "source": [
    "Process the audio with Whisper. \n",
    "\n",
    "(I'm getting Triton kernel issues when I run this. I don't know why, this is apparently a Windows problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "216e7635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dacla\\anaconda3\\Lib\\site-packages\\whisper\\timing.py:42: UserWarning: Failed to launch Triton kernels, likely due to missing CUDA toolkit; falling back to a slower median kernel implementation...\n",
      "  warnings.warn(\n",
      "c:\\Users\\dacla\\anaconda3\\Lib\\site-packages\\whisper\\timing.py:146: UserWarning: Failed to launch Triton kernels, likely due to missing CUDA toolkit; falling back to a slower DTW implementation...\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Paths for vocals and no_vocals stems\n",
    "vocals = f\"separated/mdx_extra/{song}/vocals.wav\"\n",
    "no_vocals = f\"separated/mdx_extra/{song}/no_vocals.wav\"\n",
    "\n",
    "vocals_path = os.path.join(notebook_dir, vocals)\n",
    "no_vocals_path = os.path.join(notebook_dir, no_vocals)\n",
    "\n",
    "### Apply the transcription with Whisper\n",
    "# word_timestamps=True for timestamp info\n",
    "\n",
    "# this one for running Whisper on the vocals track only\n",
    "result = model.transcribe(vocals_path, word_timestamps=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf11993",
   "metadata": {},
   "source": [
    "Here we consider the different words to look out for. I think this is the part that will need the most work in terms of NLP to figure out what to edit. Obvious bad words are easy, but there's context dependent things that will need a separate model to interpret\n",
    "\n",
    "There's also issues of knowing the probabilities of the outputs. I'm not sure how to access the 2nd or 3rd word that Whisper thinks a particular segment is, if the 2nd most-likely word is a curse word and the prob is close to the 1st this is probably worth editing. \n",
    "\n",
    "Another problem is that there are some curse words that are only offensive in pairs: e.g., \"god damn\" is not allowed but \"damn\" generally is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1e7902f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Whisper can sometimes add bits of punctuation, we don't care about those\n",
    "def remove_punctuation(s):\n",
    "    s = re.sub(r'[^a-zA-Z0-9\\s]', '', s)\n",
    "    return s.lower()\n",
    "\n",
    "all = []\n",
    "\n",
    "# Collect words\n",
    "for segment in result[\"segments\"]:\n",
    "    for word_info in segment['words']:\n",
    "        word = word_info['word'].strip()\n",
    "        word = remove_punctuation(word)\n",
    "        \n",
    "        start_time = float(word_info['start'])\n",
    "        end_time = float(word_info['end'])\n",
    "        prob = word_info['probability']\n",
    "        \n",
    "        all.append([word, start_time, end_time, prob])\n",
    "\n",
    "# Create Dataframe\n",
    "columns = ['word', 'start', 'end', 'prob']\n",
    "df_all = pd.DataFrame(all, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d96aa2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit for things to look for\n",
    "curses = {'fuck', 'shit', 'bitch', 'nigga', 'cock', 'faggot', 'cunt', 'pussy', 'dick'} #To name a few...?\n",
    "pattern = '|'.join(curses)\n",
    "\n",
    "# I noticed it can create duplicate entries for some reason, delete them then save the log to a .csv\n",
    "df_all = df_all.drop_duplicates()\n",
    "\n",
    "# Add a column which is boolean 1 for \"is curse\" and 0 for \"is not curse\"\n",
    "df_all['curse'] = df_all['word'].str.contains(pattern, case=False, na=False, regex=True).astype(int)\n",
    "\n",
    "# Save the dataframe\n",
    "df_all.to_csv(f'logs/{song}-{whisper_type}-all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "563f1e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>prob</th>\n",
       "      <th>curse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fuck</td>\n",
       "      <td>9.84</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.941962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bitch</td>\n",
       "      <td>11.34</td>\n",
       "      <td>11.44</td>\n",
       "      <td>0.610328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>niggas</td>\n",
       "      <td>17.20</td>\n",
       "      <td>17.36</td>\n",
       "      <td>0.985287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>shit</td>\n",
       "      <td>20.12</td>\n",
       "      <td>20.32</td>\n",
       "      <td>0.978746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>fuck</td>\n",
       "      <td>24.94</td>\n",
       "      <td>25.26</td>\n",
       "      <td>0.474615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>niggas</td>\n",
       "      <td>25.52</td>\n",
       "      <td>25.74</td>\n",
       "      <td>0.920795</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>niggas</td>\n",
       "      <td>35.98</td>\n",
       "      <td>36.16</td>\n",
       "      <td>0.958646</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>bitch</td>\n",
       "      <td>38.06</td>\n",
       "      <td>38.28</td>\n",
       "      <td>0.891795</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>bitch</td>\n",
       "      <td>39.22</td>\n",
       "      <td>39.36</td>\n",
       "      <td>0.138935</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>shit</td>\n",
       "      <td>42.84</td>\n",
       "      <td>43.08</td>\n",
       "      <td>0.969069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>fuck</td>\n",
       "      <td>44.18</td>\n",
       "      <td>44.34</td>\n",
       "      <td>0.273217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>niggas</td>\n",
       "      <td>44.54</td>\n",
       "      <td>44.80</td>\n",
       "      <td>0.799311</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  start    end      prob  curse\n",
       "2      fuck   9.84  10.00  0.941962      1\n",
       "8     bitch  11.34  11.44  0.610328      1\n",
       "45   niggas  17.20  17.36  0.985287      1\n",
       "61     shit  20.12  20.32  0.978746      1\n",
       "79     fuck  24.94  25.26  0.474615      1\n",
       "82   niggas  25.52  25.74  0.920795      1\n",
       "117  niggas  35.98  36.16  0.958646      1\n",
       "128   bitch  38.06  38.28  0.891795      1\n",
       "135   bitch  39.22  39.36  0.138935      1\n",
       "154    shit  42.84  43.08  0.969069      1\n",
       "157    fuck  44.18  44.34  0.273217      1\n",
       "159  niggas  44.54  44.80  0.799311      1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only those words which are curse words\n",
    "df = df_all[df_all['curse']==1]\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3b1c25cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first off fuck elon musk 8 too much bitch thats expensive put a hose in the back and a crack in the slack if i tweet and delete and i meant it i dont really need a check cause i got no respect and these niggas might not be like a dentist city all about free speech still he had some shit in his head and his fingers this aint what you want no this aint what you want fuck y all niggas i feel like papa john left respect to the bank im tony khan and they hate what i say cause i aint wrong what kind of rabbit is this the kind of man rat niggas miss you know it i put a throw in my bitch gotta push it in finna like bitch she know it you think its me texting with kids it doesnt get stranger than this thats oh shit i dont fuck you niggas like im unfugged wait i am me written eyes with a shot of repeat while you stretching the truth in your tweets ive been stretching it girl i am she once a deets in the crib you get so under for weeks watch your energy watch what you tweet you gon feel like you aint finished reposic reposic the agora can i call my cell and then i get cost always out of my is target of them team remiana jesse d if you head girl a rap break she can stop thinking about me so travel up like a pin up trap go ahead girl you dont think so whats up with that whats up spitting fast like bust up if i need to trust it feel like i love ya\n"
     ]
    }
   ],
   "source": [
    "## Inspect the full lyrics\n",
    "full_text = \" \".join(df_all['word'].tolist())\n",
    "print(full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c655beb",
   "metadata": {},
   "source": [
    "This function does the actual editing. Using the curses identified in df, mute the *audio* track only at the specified times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "76028ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydub does the audio effects\n",
    "from pydub import AudioSegment\n",
    "\n",
    "## Applies silecning to input_audio_path at given list of times \n",
    "def silence_audio_segment(input_audio_path, output_audio_path, times):\n",
    "    \n",
    "    print(f'Applying silencing edits to vocals: {input_audio_path}')\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(input_audio_path)\n",
    "    for (start_ms, end_ms) in times:\n",
    "        # Select times to reverse\n",
    "        before_segment = audio[:start_ms]\n",
    "\n",
    "        # -60dB to the audio effectively mutes it\n",
    "        target_segment = audio[start_ms:end_ms] - 60\n",
    "\n",
    "        after_segment = audio[end_ms:]\n",
    "\n",
    "        # Concatenate: this can be made faster, but it's not a priority\n",
    "        audio = before_segment + target_segment + after_segment\n",
    "\n",
    "    # Export the modified audio\n",
    "    print(f'Outputting edited vocals to {output_audio_path}')             \n",
    "    audio.export(output_audio_path, format='wav') \n",
    "    return\n",
    "\n",
    "# Combines two audio tracks via their paths (vocals and instruments for example)\n",
    "def combine_audio(path1, path2, outpath):\n",
    "    audio1 = AudioSegment.from_file(path1, format='wav')\n",
    "    audio2 = AudioSegment.from_file(path2, format='wav')\n",
    "\n",
    "    combined_audio = audio1.overlay(audio2)\n",
    "\n",
    "    # format='mp3' for mp3 files   \n",
    "    combined_audio.export(outpath, format=\"mp3\") \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a3422a",
   "metadata": {},
   "source": [
    "Mute the explicit content, then recombines the vocals and no_vocals tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b3aaa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying silencing edits to vocals: c:\\Users\\dacla\\Documents\\auto-censoring-local\\separated/mdx_extra/jpeg/vocals.wav\n",
      "Outputting edited vocals to c:\\Users\\dacla\\Documents\\auto-censoring-local\\separated/mdx_extra/jpeg/vocals.wav\n",
      "Combining the audio...\n",
      "Exported to c:\\Users\\dacla\\Documents\\auto-censoring-local\\music/jpeg-large-v3-turbo-edit.mp3\n"
     ]
    }
   ],
   "source": [
    "## Maybe a bit inefficient\n",
    "times = []\n",
    "for row in df.itertuples():\n",
    "    #word = row[1]\n",
    "    start = int(row[2]*1000)\n",
    "    end = int(row[3]*1000)\n",
    "    times.append((start, end))\n",
    "\n",
    "# Run the silencing script\n",
    "silence_audio_segment(vocals_path, vocals_path, times)\n",
    "\n",
    "## Output file name\n",
    "output_file = f\"music/{song}-{whisper_type}-edit.mp3\"\n",
    "output_path = os.path.join(notebook_dir, output_file)\n",
    "\n",
    "print('Combining the audio...')\n",
    "combine_audio(vocals_path, no_vocals_path, output_path)\n",
    "print(f'Exported to {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0d57bd",
   "metadata": {},
   "source": [
    "Last step is to transfer the metadata from the original track to the edited track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8f1cd156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mutagen.easyid3 import EasyID3\n",
    "\n",
    "# Transfer the metadata from the original to the edited track\n",
    "def transfer_metadata(original_audio_path, edited_audio_path):\n",
    "    \n",
    "    audio_orig = EasyID3(original_audio_path)\n",
    "    audio_edit = EasyID3(edited_audio_path)\n",
    "\n",
    "    metadata = dict()\n",
    "\n",
    "    ## Add more if wanted\n",
    "    metadata['title'] = audio_orig.get('title', [None])[0]\n",
    "    metadata['artist'] = audio_orig.get('artist', [None])[0]\n",
    "    metadata['album'] = audio_orig.get('album', [None])[0]\n",
    "    metadata['date'] = audio_orig.get('date', [None])[0] # Often 'year' or full date\n",
    "    metadata['tracknumber'] = audio_orig.get('tracknumber', [None])[0]\n",
    "    \n",
    "    # Apply metadata to edited track\n",
    "    for key, value in metadata.items():\n",
    "        audio_edit[key] = [str(value)]\n",
    "\n",
    "    # and save\n",
    "    audio_edit.save()\n",
    "    return\n",
    "        \n",
    "transfer_metadata(original_audio_path=full_audio_path,\n",
    "                  edited_audio_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c14c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
