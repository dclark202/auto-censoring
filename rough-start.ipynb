{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c559b678",
   "metadata": {},
   "source": [
    "Basic template for using untrained Whisper to detect singular curse words in a music track. Demucs is used to split the audio first then the vocals tracks is muted during the curse words. \n",
    "\n",
    "Probably everything should be done with .wav files to preserve audio integrity. There's also a lot of temp files that get created that could be deleted at the end (the separated tracks)\n",
    "\n",
    "Needed packages:\n",
    "- Whisper (incl pytorch, torchaudio)\n",
    "- Demucs (vocals stem separation)\n",
    "- ffmpeg (for mp3)\n",
    "- soundfile (for wav)\n",
    "- pydub (for editing audio files)\n",
    "- mutagen (for preserving metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14df4a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Check for cuda/cpu\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device}')\n",
    "\n",
    "# Load the model. I've tired the following:\n",
    "# large-v3-turbo, large-v3, medium.en (english only), large (needs 10GB of VRAM and takes FOREVER)\n",
    "model = whisper.load_model(\"large-v3-turbo\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aced78",
   "metadata": {},
   "source": [
    "Get file location and audio path, split into vocals and instruments. Demucs does a bunch of things automatically perhaps we can investigate further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2c55779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import demucs.separate\n",
    "import os\n",
    "\n",
    "# I put a few tracks in here\n",
    "song = 'big'\n",
    "audio_file = f\"music/{song}.mp3\"\n",
    "\n",
    "# Format file path\n",
    "notebook_dir = os.getcwd()\n",
    "full_audio_path = os.path.join(notebook_dir, audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "802afae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model is a bag of 4 models. You will see that many progress bars per track.\n",
      "Separated tracks will be stored in C:\\Users\\dacla\\Documents\\auto-censoring-local\\separated\\mdx_extra\n",
      "Separating track c:\\Users\\dacla\\Documents\\auto-censoring-local\\music\\big.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 330.0/330.0 [00:03<00:00, 99.80seconds/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 330.0/330.0 [00:03<00:00, 93.22seconds/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 330.0/330.0 [00:03<00:00, 102.40seconds/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 330.0/330.0 [00:03<00:00, 103.61seconds/s]\n"
     ]
    }
   ],
   "source": [
    "# Split the vocals with demucs\n",
    "demucs.separate.main([\"--two-stems\", \"vocals\", \"-n\", \"mdx_extra\", full_audio_path])\n",
    "\n",
    "# Comments:\n",
    "# Add \"--mp3\" command for output in mp3 format. But .wav is lossless and will probably (?) sound better\n",
    "# listening with headphones the audio processed with --mp3 sounded pretty weird\n",
    "# mdx_extra is just one of the models included in demucs. try other models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06484b1d",
   "metadata": {},
   "source": [
    "Process the audio with Whisper. \n",
    "\n",
    "(I'm getting Triton kernel issues when I run this. I don't know why, this is apparently a Windows problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "216e7635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dacla\\anaconda3\\Lib\\site-packages\\whisper\\timing.py:42: UserWarning: Failed to launch Triton kernels, likely due to missing CUDA toolkit; falling back to a slower median kernel implementation...\n",
      "  warnings.warn(\n",
      "c:\\Users\\dacla\\anaconda3\\Lib\\site-packages\\whisper\\timing.py:146: UserWarning: Failed to launch Triton kernels, likely due to missing CUDA toolkit; falling back to a slower DTW implementation...\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Paths for vocals and no_vocals stems\n",
    "vocals = f\"separated/mdx_extra/{song}/vocals.wav\"\n",
    "no_vocals = f\"separated/mdx_extra/{song}/no_vocals.wav\"\n",
    "\n",
    "vocals_path = os.path.join(notebook_dir, vocals)\n",
    "no_vocals_path = os.path.join(notebook_dir, no_vocals)\n",
    "\n",
    "### Apply the transcription with Whisper\n",
    "\n",
    "# word_timestamps=True for timestamp info\n",
    "\n",
    "# this one for running Whisper on the vocals track only\n",
    "result = model.transcribe(vocals_path, word_timestamps=True)\n",
    "\n",
    "\n",
    "## or run on the full track\n",
    "#result = model.transcribe(full_audio_path, word_timestamps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf11993",
   "metadata": {},
   "source": [
    "Here we consider the different words to look out for. I think this is the part that will need the most work in terms of NLP to figure out what to edit. Obvious bad words are easy, but there's context dependent things that will need a separate model to interpret\n",
    "\n",
    "There's also issues of knowing the probabilities of the outputs. I'm not sure how to access the 2nd or 3rd word that Whisper thinks a particular segment is, if the 2nd most-likely word is a curse word and the prob is close to the 1st this is probably worth editing. \n",
    "\n",
    "Another problem is that there are some curse words that are only offensive in pairs: e.g., \"god damn\" is not allowed but \"damn\" generally is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e7902f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit for things to look for\n",
    "curses = {'fuck', 'motherfucker', 'shit', 'bitch', 'nigga', 'cock', } #To name a few...?\n",
    "to_add = []\n",
    "all = []\n",
    "\n",
    "# Collect words\n",
    "for segment in result[\"segments\"]:\n",
    "    for word_info in segment['words']:\n",
    "        all.append([word_info['word'].strip().lower(), float(word_info['start']), float(word_info['end']), word_info['probability']])\n",
    "        for curse in curses:\n",
    "            if curse in word_info['word'].strip().lower():\n",
    "                to_add.append([word_info['word'].strip().lower(), float(word_info['start']), float(word_info['end']), word_info['probability']])\n",
    "        \n",
    "\n",
    "# Create Dataframe\n",
    "columns = ['word', 'start', 'end', 'prob']\n",
    "df = pd.DataFrame(to_add, columns=columns)\n",
    "df_all = pd.DataFrame(all, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ab1c7",
   "metadata": {},
   "source": [
    "Inspect the words identified by Whisper, save log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de41121b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shit.</td>\n",
       "      <td>59.48</td>\n",
       "      <td>59.88</td>\n",
       "      <td>0.003777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shitting</td>\n",
       "      <td>235.68</td>\n",
       "      <td>236.00</td>\n",
       "      <td>0.590071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shit</td>\n",
       "      <td>241.22</td>\n",
       "      <td>241.42</td>\n",
       "      <td>0.381918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word   start     end      prob\n",
       "0     shit.   59.48   59.88  0.003777\n",
       "1  shitting  235.68  236.00  0.590071\n",
       "2      shit  241.22  241.42  0.381918"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect dataframe\n",
    "df = df.drop_duplicates()\n",
    "df_all = df_all.drop_duplicates()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7bbf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv if desired\n",
    "df.to_csv(f'logs/{song}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d62e061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you. Thank you. Don't be cross this sick I want. I've seen the boss bling on and on. Fake concerns is what's the matter man. And you think I ought to shake your motherfucking hand. Well, I know how much you care. Don't be cross this sick I want. I've seen the boss bling on and on. Come here by me. I want you here. Nightmares come me. It's so fucking clear. I want you here. Don't be cross this sick I want. I've seen the boss bling on and on. Come here by me. I want you here. Nightmares come me. It's so fucking clear. Nightmares come me. It's so fucking clear. Nightmares come me. I want you here. Nightmares come me. Nightmares come me. I want you here.\n"
     ]
    }
   ],
   "source": [
    "## Print full transcript\n",
    "full_text = result[\"text\"].strip()\n",
    "print(full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c655beb",
   "metadata": {},
   "source": [
    "This function does the actual editing. I have two procedures here, one which reverses the whole track and the other which mutes the *audio* track (ideally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76028ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydub does the audio effects\n",
    "from pydub import AudioSegment\n",
    "\n",
    "## Applies silecning to input_audio_path at given list of times \n",
    "def silence_audio_segment(input_audio_path, output_audio_path, times):\n",
    "    \n",
    "    print(f'Applying silencing edits to vocals: {input_audio_path}')\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(input_audio_path)\n",
    "    for (start_ms, end_ms) in times:\n",
    "        # Select times to reverse\n",
    "        before_segment = audio[:start_ms]\n",
    "\n",
    "        # -60dB to the audio effectively mutes it\n",
    "        target_segment = audio[start_ms:end_ms] - 60\n",
    "\n",
    "        after_segment = audio[end_ms:]\n",
    "\n",
    "        # Concatenate\n",
    "        audio = before_segment + target_segment + after_segment\n",
    "\n",
    "    # Export the modified audio\n",
    "    print(f'Outputting edited vocals to {output_audio_path}')\n",
    "    audio.export(output_audio_path, format=\"wav\") \n",
    "    return\n",
    "\n",
    "# Combines two audio tracks via their paths (vocals and instruments for example)\n",
    "def combine_audio(path1, path2, outpath):\n",
    "    audio1 = AudioSegment.from_file(path1, format='wav')\n",
    "    audio2 = AudioSegment.from_file(path2, format='wav')\n",
    "\n",
    "    combined_audio = audio1.overlay(audio2)\n",
    "\n",
    "    # format='mp3' for mp3 files\n",
    "    combined_audio.export(outpath, format=\"wav\") \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a3422a",
   "metadata": {},
   "source": [
    "Mute the explicit content, then recombines the vocals and no_vocals tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b3aaa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying silencing edits to vocals: c:\\Users\\dacla\\Documents\\auto-censoring-local\\separated/mdx_extra/big/vocals.wav\n",
      "Outputting edited vocals to c:\\Users\\dacla\\Documents\\auto-censoring-local\\separated/mdx_extra/big/vocals.wav\n",
      "Combining the audio...\n",
      "Exported to c:\\Users\\dacla\\Documents\\auto-censoring-local\\music/big-edit-silenced.wav\n"
     ]
    }
   ],
   "source": [
    "## Maybe a bit inefficient\n",
    "times = []\n",
    "for row in df.itertuples():\n",
    "    #word = row[1]\n",
    "    start = int(row[2]*1000)\n",
    "    end = int(row[3]*1000)\n",
    "    times.append((start, end))\n",
    "\n",
    "# Run the silencing script\n",
    "silence_audio_segment(vocals_path, vocals_path, times)\n",
    "\n",
    "## Output file name\n",
    "output_file = f\"music/{song}-edit-silenced.wav\"\n",
    "output_path = os.path.join(notebook_dir, output_file)\n",
    "\n",
    "print('Combining the audio...')\n",
    "combine_audio(vocals_path, no_vocals_path, output_path)\n",
    "print(f'Exported to {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37108ccc",
   "metadata": {},
   "source": [
    "Method 2 for reversing the entire track. It's less pleasing to the ear honestly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a81207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse track at specified times\n",
    "def reverse_audio_segment(input_audio_path, output_audio_path, times):\n",
    "    print(f'Applying reverse edits to: {input_audio_path}')\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(input_audio_path)\n",
    "    for (start_ms, end_ms) in times:\n",
    "        # Select times to reverse\n",
    "        before_segment = audio[:start_ms]\n",
    "\n",
    "\n",
    "        target_segment = audio[start_ms:end_ms]\n",
    "        target_segment = target_segment.reverse()\n",
    "\n",
    "        after_segment = audio[end_ms:]\n",
    "\n",
    "        # Concatenate\n",
    "        audio = before_segment + target_segment + after_segment\n",
    "\n",
    "    # Export the modified audio\n",
    "    print(f'Outputting audio to {output_audio_path}')\n",
    "    audio.export(output_audio_path, format=\"wav\") \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b455f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(66400, 66800), (67540, 67900), (104340, 104620), (119340, 119620), (124360, 125040), (130060, 130240)]\n",
      "Applying edits to: c:\\Users\\dacla\\Documents\\auto-censoring\\separated\\mdx_extra\\5th-ward\\vocals.mp3\n",
      "Outputting audio to output.mp3\n"
     ]
    }
   ],
   "source": [
    "# Path formatting\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "input_file = f\"music/{song}.wav\"\n",
    "output_file = f\"music/{song}-edit-reversed.wav\"\n",
    "\n",
    "input_path = os.path.join(notebook_dir, input_file)\n",
    "output_path = os.path.join(notebook_dir, output_file)\n",
    "\n",
    "## Maybe a bit inefficient\n",
    "times = []\n",
    "for row in df.itertuples():\n",
    "    #word = row[1]\n",
    "    start = int(row[2]*1000)\n",
    "    end = int(row[3]*1000)\n",
    "    times.append((start, end))\n",
    "\n",
    "# Run the reversing script\n",
    "reverse_audio_segment(input_path, output_path, times)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
