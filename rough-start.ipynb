{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c559b678",
   "metadata": {},
   "source": [
    "Basic template for using untrained Whisper to detect singular curse words in a music track. Demucs is used to split the audio first then the vocals tracks is muted during the curse words. \n",
    "\n",
    "Probably everything should be done with .wav files to preserve audio integrity. There's also a lot of temp files that get created that could be deleted at the end (the separated tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14df4a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Check for cuda/cpu\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device}')\n",
    "\n",
    "# Load the model: large-v3-turbo or large-v3\n",
    "model = whisper.load_model(\"large-v3-turbo\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aced78",
   "metadata": {},
   "source": [
    "Get file location and audio path, split into vocals and instruments. Demucs does a bunch of things automatically perhaps we can investigate further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c2c55779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model is a bag of 4 models. You will see that many progress bars per track.\n",
      "Separated tracks will be stored in C:\\Users\\dacla\\Documents\\auto-censoring\\separated\\mdx_extra\n",
      "Separating track c:\\Users\\dacla\\Documents\\auto-censoring\\music\\clint.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 363.0/363.0 [00:03<00:00, 102.11seconds/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 363.0/363.0 [00:03<00:00, 97.98seconds/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 363.0/363.0 [00:03<00:00, 98.78seconds/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 363.0/363.0 [00:03<00:00, 104.37seconds/s]\n"
     ]
    }
   ],
   "source": [
    "import demucs.separate\n",
    "\n",
    "# I put a few tracks in here\n",
    "song = 'clint'\n",
    "audio_file = f\"music/{song}.mp3\"\n",
    "\n",
    "# Format file path\n",
    "notebook_dir = os.getcwd()\n",
    "full_audio_path = os.path.join(notebook_dir, audio_file)\n",
    "\n",
    "# Split the vocals with demucs\n",
    "# There's some parameters here that could be improved on\n",
    "demucs.separate.main([\"--mp3\", \"--two-stems\", \"vocals\", \"-n\", \"mdx_extra\", full_audio_path])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "216e7635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dacla\\anaconda3\\Lib\\site-packages\\whisper\\timing.py:42: UserWarning: Failed to launch Triton kernels, likely due to missing CUDA toolkit; falling back to a slower median kernel implementation...\n",
      "  warnings.warn(\n",
      "c:\\Users\\dacla\\anaconda3\\Lib\\site-packages\\whisper\\timing.py:146: UserWarning: Failed to launch Triton kernels, likely due to missing CUDA toolkit; falling back to a slower DTW implementation...\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Paths for vocals and no_vocals stems\n",
    "vocals = f\"separated/mdx_extra/{song}/vocals.mp3\"\n",
    "no_vocals = f\"separated/mdx_extra/{song}/no_vocals.mp3\"\n",
    "\n",
    "vocals_path = os.path.join(notebook_dir, vocals)\n",
    "no_vocals_path = os.path.join(notebook_dir, no_vocals)\n",
    "\n",
    "### Apply the transcription with Whisper\n",
    "\n",
    "# word_timestamps=True for timestamp info\n",
    "# Getting Triton kernel issues when I run this ?\n",
    "result = model.transcribe(vocals_path, word_timestamps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf11993",
   "metadata": {},
   "source": [
    "Here we consider the different words to look out for. I think this is the part that will need the most work in terms of NLP to figure out what to edit. Obvious bad words are easy, but there's context dependent things that will need a separate model to interpret\n",
    "\n",
    "There's also issues of knowing the probabilities of the outputs. I'm not sure how to access the 2nd or 3rd word that Whisper thinks a particular segment is, if the 2nd most-likely word is a curse word and the prob is close to the 1st this is probably worth editing. \n",
    "\n",
    "Another problem is that there are some curse words that are only offensive in pairs: e.g., \"god damn\" is not allowed but \"damn\" generally is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e7902f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit for things to look for\n",
    "curses = {'fuck', 'motherfucker', 'shit', 'bitch', 'nigga', 'cock', } #To name a few...?\n",
    "to_add = []\n",
    "all = []\n",
    "\n",
    "# Collect words\n",
    "for segment in result[\"segments\"]:\n",
    "    for word_info in segment['words']:\n",
    "        all.append([word_info['word'].strip().lower(), float(word_info['start']), float(word_info['end']), word_info['probability']])\n",
    "        for curse in curses:\n",
    "            if curse in word_info['word'].strip().lower():\n",
    "                to_add.append([word_info['word'].strip().lower(), float(word_info['start']), float(word_info['end']), word_info['probability']])\n",
    "        \n",
    "\n",
    "# Create Dataframe\n",
    "columns = ['word', 'start', 'end', 'prob']\n",
    "df = pd.DataFrame(to_add, columns=columns)\n",
    "df_all = pd.DataFrame(all, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ab1c7",
   "metadata": {},
   "source": [
    "Inspect the words identified by Whisper, save log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "de41121b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shit,</td>\n",
       "      <td>80.94</td>\n",
       "      <td>81.22</td>\n",
       "      <td>0.394846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fucking</td>\n",
       "      <td>132.84</td>\n",
       "      <td>133.10</td>\n",
       "      <td>0.607768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>motherfuckers</td>\n",
       "      <td>149.04</td>\n",
       "      <td>149.78</td>\n",
       "      <td>0.998553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word   start     end      prob\n",
       "0          shit,   80.94   81.22  0.394846\n",
       "1        fucking  132.84  133.10  0.607768\n",
       "2  motherfuckers  149.04  149.78  0.998553"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect dataframe\n",
    "df = df.drop_duplicates()\n",
    "df_all = df_all.drop_duplicates()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7bbf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "df.to_csv(f'logs/{song}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0d62e061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ain't happy, I'm feeling glad I got sunshine In a bag I'm useless, but not for long The future is coming on I ain't happy, I'm feeling glad I got sunshine In a bag I'm useless, but not for long The future is coming on It's coming on It's coming on Finally, someone let me out of my cage Now, time for me is nothing because I'm counting no A's Nah, I couldn't be there Nah, you shouldn't be scared I'm good at repairs And I'm under each snare Intangible Bet you didn't think so I command you to panoramic view Look, I'll make it all manageable Pick and choose, sit and lose All you different crews Chicks and dudes Who you think is really kicking tunes Picture you getting down in a picture tube Like you lit the fuse You think it's fictional, mystical, maybe Spiritual Hero who appears in you to clear your view When you're too crazy Lifeless to those The definition for what life is Priceless to you Because I put you on the hype Shit, you like it Gunsmoking righteous with one token You're psychic among no possesses you with one though Ain't happy I'm feeling glad I got sunshine In a bag I'm useless Not for long The future Is coming on Ain't happy I'm feeling glad I got sunshine In a bag I'm useless Not for long The future Is coming on It's coming on It's coming on It's coming on It's coming on The essence The basics Without it you make it Allow me to make this Child like your nature Rhythm You have it or you don't That's a fallacy I'm in them Every sprouting tree Every child of peace Every cloud and seed You see with your eyes And see destruction and demise Corruption in disguise From this fucking enterprise Now I'm sucked into your lies Through Russell Not his muscles But percussion to provide With me as a guide Y'all can see me now Cause you don't see with your eye You perceive with your mind That's the inner So I'ma stick around with Russ And be a mentor Bust a few rhymes So motherfuckers remember What the thought is I brought all this So you can survive When law is lawless Right here Feeling sensations That you thought were dead No squealing Remember that it's all in your head Hey, it happened I'm feeling glad I got sunshine In a bag I'm useless Not for long The future Is coming on Hey, it happened I'm feeling glad I got sunshine I got sunshine In a bag I'm useless Not for long My future Is coming on Is coming on Is coming on My future Is coming on My future Is coming on My future Is coming on is coming on my future. Thank you. Thank you. Thank you. Thank you.\n"
     ]
    }
   ],
   "source": [
    "## Print full transcript\n",
    "full_text = result[\"text\"].strip()\n",
    "print(full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c655beb",
   "metadata": {},
   "source": [
    "This function does the actual editing. I have two procedures here, one which reverses the whole track and the other which mutes the *audio* track (ideally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76028ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydub does the audio effects\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def reverse_audio_segment(input_audio_path, output_audio_path, times):\n",
    "    print(f'Applying reverse edits to: {input_audio_path}')\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(input_audio_path)\n",
    "    for (start_ms, end_ms) in times:\n",
    "        # Select times to reverse\n",
    "        before_segment = audio[:start_ms]\n",
    "\n",
    "\n",
    "        target_segment = audio[start_ms:end_ms]\n",
    "        target_segment = target_segment.reverse()\n",
    "\n",
    "        after_segment = audio[end_ms:]\n",
    "\n",
    "        # Concatenate\n",
    "        audio = before_segment + target_segment + after_segment\n",
    "\n",
    "    # Export the modified audio\n",
    "    print(f'Outputting audio to {output_audio_path}')\n",
    "    audio.export(output_audio_path, format=\"mp3\") \n",
    "    return\n",
    "\n",
    "## Applies silecning to input_audio_path at given list of times \n",
    "def silence_audio_segment(input_audio_path, output_audio_path, times):\n",
    "    \n",
    "    print(f'Applying silencing edits to vocals: {input_audio_path}')\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(input_audio_path)\n",
    "    for (start_ms, end_ms) in times:\n",
    "        # Select times to reverse\n",
    "        before_segment = audio[:start_ms]\n",
    "\n",
    "        # -60dB to the audio effectively mutes it\n",
    "        target_segment = audio[start_ms:end_ms] - 60\n",
    "\n",
    "        after_segment = audio[end_ms:]\n",
    "\n",
    "        # Concatenate\n",
    "        audio = before_segment + target_segment + after_segment\n",
    "\n",
    "    # Export the modified audio\n",
    "    print(f'Outputting edited vocals to {output_audio_path}')\n",
    "    audio.export(output_audio_path, format=\"mp3\") \n",
    "    return\n",
    "\n",
    "# Combines two audio tracks via their paths (vocals and instruments for example)\n",
    "def combine_audio(path1, path2, outpath):\n",
    "    audio1 = AudioSegment.from_file(path1, format='mp3')\n",
    "    audio2 = AudioSegment.from_file(path2, format='mp3')\n",
    "\n",
    "    combined_audio = audio1.overlay(audio2)\n",
    "    combined_audio.export(outpath, format=\"mp3\") \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a3422a",
   "metadata": {},
   "source": [
    "Method 1 uses the vocals track to mute the bad words. Then recombines the vocals and no_vocals tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b3aaa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying silencing edits to vocals: c:\\Users\\dacla\\Documents\\auto-censoring\\separated/mdx_extra/clint/vocals.mp3\n",
      "Outputting edited vocals to c:\\Users\\dacla\\Documents\\auto-censoring\\separated/mdx_extra/clint/vocals.mp3\n",
      "Combining the audio...\n",
      "Exported to c:\\Users\\dacla\\Documents\\auto-censoring\\music/clint-edit-silenced.mp3\n"
     ]
    }
   ],
   "source": [
    "## Maybe a bit inefficient\n",
    "times = []\n",
    "for row in df.itertuples():\n",
    "    #word = row[1]\n",
    "    start = int(row[2]*1000)\n",
    "    end = int(row[3]*1000)\n",
    "    times.append((start, end))\n",
    "\n",
    "# Run the silencing script\n",
    "silence_audio_segment(vocals_path, vocals_path, times)\n",
    "\n",
    "## Output file name\n",
    "output_file = f\"music/{song}-edit-silenced.mp3\"\n",
    "output_path = os.path.join(notebook_dir, output_file)\n",
    "\n",
    "print('Combining the audio...')\n",
    "combine_audio(vocals_path, no_vocals_path, output_path)\n",
    "print(f'Exported to {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37108ccc",
   "metadata": {},
   "source": [
    "Method 2 for reversing the entire track. It's less pleasing to the ear honestly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0b455f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(66400, 66800), (67540, 67900), (104340, 104620), (119340, 119620), (124360, 125040), (130060, 130240)]\n",
      "Applying edits to: c:\\Users\\dacla\\Documents\\auto-censoring\\separated\\mdx_extra\\5th-ward\\vocals.mp3\n",
      "Outputting audio to output.mp3\n"
     ]
    }
   ],
   "source": [
    "# Path formatting\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "input_file = f\"music/{song}.mp3\"\n",
    "output_file = f\"music/{song}-edit-reversed.mp3\"\n",
    "\n",
    "input_path = os.path.join(notebook_dir, input_file)\n",
    "output_path = os.path.join(notebook_dir, output_file)\n",
    "\n",
    "## Maybe a bit inefficient\n",
    "times = []\n",
    "for row in df.itertuples():\n",
    "    #word = row[1]\n",
    "    start = int(row[2]*1000)\n",
    "    end = int(row[3]*1000)\n",
    "    times.append((start, end))\n",
    "\n",
    "# Run the reversing script\n",
    "reverse_audio_segment(input_path, output_path, times)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
