{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3ed6aee",
   "metadata": {},
   "source": [
    "### Normalization consists of the following line-by-line process:\n",
    "\n",
    "##### 1. Remove all lines containing nan or non-English characters\n",
    "- For best results, this should happen after transcript is shortened to match with words\n",
    "- Small complication here: before subsequent cleaning, some words don't look like English. Chicken or the egg?\n",
    "\n",
    "##### 2. Collapse 3+ consecutive occurrences of same letter to 2 letters, e.g. moooooo -> moo (timestamps unchanged)\n",
    "- Some words, like hmm, moo, bzz need two consecutive letters\n",
    "- Most words, like fuuck, do not\n",
    "- So after reducing 3+ occurrences to 2, is a dictionary/wordfreq check good enough to say whether an additional letter should be deleted?\n",
    "- Most legit way to do this would be to check how such words are tokenized in Whisper model\n",
    "- woo, oh, no, ah, eyow, go, hm | hmm, \n",
    "- leave lalala alone\n",
    "- change yey to yay\n",
    "\n",
    "##### 3. Check every word to see if it's a word\n",
    "- Might be better to use known dictionary on first pass to get dictionary-standard words before dealing with slang/spelling variants\n",
    "- Backup word test could be passes zipf_frequency test\n",
    "- If not, check if it should be combined with a nearby word fragment(s) to create an actual word, e.g. ci ty -> city. Or a double letter should be changed to a single letter, e.g. \"yees\" -> \"yes\"\n",
    "- Deal with misspellings by combining spell-checker and phonetics-checker\n",
    "\n",
    "\n",
    "### To-Do:\n",
    "\n",
    "##### 1. Combine word chunks and separate illegal compound words\n",
    "- Separated words work pretty good, but they're worsened by the absence of apostrophes like in \"we've\"\n",
    "\n",
    "##### 2. Cut off transcripts at beginning and end if they don't match with words\n",
    "- This should also involve changing audio chunks; will need to write down new start and end times of each chunk\n",
    "- Shortening audio chunks should be automated (with quality/file type preserved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f855f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from wordfreq import zipf_frequency\n",
    "import jiwer\n",
    "import re\n",
    "import numpy as np\n",
    "import enchant\n",
    "from spellchecker import SpellChecker\n",
    "from itertools import combinations\n",
    "from transformers import WhisperProcessor\n",
    "import fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5523002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First and last names used in checking if lyrics are valid words\n",
    "df_male = pd.read_csv('./data/male.txt',header=None,names=[\"name\"])\n",
    "df_female = pd.read_csv('./data/female.txt',header=None,names=[\"name\"])\n",
    "df_last = pd.read_csv('./data/Names_2010Census.csv',usecols = ['name'])\n",
    "\n",
    "df_names = pd.concat([df_male, df_female,df_last], ignore_index=True)\n",
    "\n",
    "# British spellings used to correct spelling later\n",
    "brit_to_us = pd.read_json('./data/british_to_american_sp.json', orient='index')\n",
    "brit_to_us.reset_index(inplace=True)\n",
    "brit_to_us.columns = ['british', 'american']\n",
    "brit_to_us = brit_to_us[~brit_to_us['british'].isin(['aeroplane', 'aluminium', 'buses', 'axe', 'aesthetic'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a180b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean metadata-full-lines.csv to have same format as metadata-lines.csv\n",
    "df = pd.read_csv(\"../../data/metadata-full-lines.csv\", usecols=[\"filename\", \"words\", \"transcript\"])\n",
    "df = df.rename(columns={\"words\": \"transcript\", \"transcript\": \"words\"})\n",
    "df = df[[\"filename\", \"words\", \"transcript\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baaaf1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove bad songs (non-English, transcription/lyrics issues, etc.)\n",
    "df_bad = pd.read_csv('./data/bad_songs.csv')\n",
    "df_bad['filename'] = df_bad['filename'].str.replace(r'^\\d+\\.\\s*', '', regex=True)   # remove number + period + spaces at the start\n",
    "df_bad['filename'] = df_bad['filename'].str.replace(r'\\s+', '', regex=True) # delete whitespace\n",
    "\n",
    "# Build a tuple of bad prefixes\n",
    "bad_prefixes = tuple(df_bad['filename'].values)\n",
    "\n",
    "# Filter rows where 'filename' starts with any bad prefix\n",
    "mask = df['filename'].str.startswith(bad_prefixes)\n",
    "\n",
    "df = df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3300fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correctly format all lines (including nan formatting)\n",
    "def parse_and_check_for_nan(val):\n",
    "    if isinstance(val, str):\n",
    "        nan_count = len(re.findall(r\"'word': nan\", val))\n",
    "        if nan_count > 0:\n",
    "            print(f\"'word': nan appears {nan_count} times\")\n",
    "\n",
    "        val_fixed = re.sub(r\"'word': nan\", \"'word': np.nan\", val)\n",
    "        try:\n",
    "            parsed = eval(val_fixed, {\"np\": np})\n",
    "            if any(pd.isna(item.get('word')) for item in parsed):\n",
    "                return None\n",
    "            return parsed\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Format all lines and remove those containing nan\n",
    "df['words'] = df['words'].apply(parse_and_check_for_nan)\n",
    "df = df.dropna(subset=['words']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eaedb9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename                 00d5c65d644c4a549e7d501d65397b7b-3.wav\n",
       "transcript                                     you away with me\n",
       "words         [{'word': 'you', 'start': 0.0, 'end': 0.219}, ...\n",
       "Name: 150, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['filename','transcript','words']].iloc[150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cd6b4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text: delete puctuation (keep apostrophes), collapse multiple spaces\n",
    "df['transcript_no_punct'] = (\n",
    "    df['transcript']\n",
    "    .str.replace(r'(?<=\\S)-(?=\\S)', ' ', regex=True)  # Hyphen surrounded by non-space\n",
    "    .str.replace(r'\\s*-\\s*', '', regex=True) # Hyphen with space on either side\n",
    "    .str.replace(r\"[^\\w\\s'-]\", '', regex=True)  # Remove unwanted punctuation\n",
    "    .str.replace(r\"_\", \"\", regex=True)          # Remove underscores\n",
    "    .str.replace(r\"\\s+\", ' ', regex=True)       # Collapse multiple spaces\n",
    "    .str.strip()\n",
    "    .str.replace(r\"^'+(.*?)'+$\", r\"\\1\", regex=True) # Happens twice to remove outer apostrophes for things like ''you''\n",
    "    .str.replace(r\"^'+(.*?)'+$\", r\"\\1\", regex=True) # See above\n",
    ")\n",
    "\n",
    "# Clean 'words' by deleting duplicate timestamps\n",
    "def remove_duplicate_dicts(lst):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for d in lst:\n",
    "        key = tuple(sorted(d.items()))\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            result.append(d)\n",
    "    return result\n",
    "\n",
    "# Clean 'words' by deleting timestamps which end before they start\n",
    "def remove_invalid_time_dicts(lst):\n",
    "    return [d for d in lst if d.get('end', 0) >= d.get('start', 0)]\n",
    "\n",
    "# Get rid of duplicate and invalid timestamps\n",
    "df['words'] = df['words'].apply(lambda lst: remove_invalid_time_dicts(remove_duplicate_dicts(lst)) if isinstance(lst, list) else lst)\n",
    "\n",
    "# Create column without timestamps\n",
    "df['words_no_time'] = df['words'].apply(lambda lst: \" \".join(item['word'] for item in lst) if isinstance(lst, list) else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb92f380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to further align transcript with words\n",
    "def extract_aligned_words(row):\n",
    "    transcript_words = row['transcript_no_punct'].split()\n",
    "    words_no_time = row['words_no_time'].replace(\" \", \"\").replace(\"'\", \"\")\n",
    "\n",
    "    aligned_words = []\n",
    "    for word in transcript_words:\n",
    "        clean_word = word.replace(\"'\", \"\")\n",
    "        pointer = 0\n",
    "        for char in clean_word:\n",
    "            pointer = words_no_time.find(char, pointer)\n",
    "            if pointer == -1:\n",
    "                break\n",
    "            pointer += 1\n",
    "        else:\n",
    "            aligned_words.append(word)\n",
    "\n",
    "    return \" \".join(aligned_words)\n",
    "\n",
    "df['transcript_words_align'] = df.apply(extract_aligned_words, axis=1)\n",
    "\n",
    "# Used to further align transcript with words\n",
    "def intersect_words_with_transcript_align(row):\n",
    "    transcript_words = row['transcript_words_align'].split()\n",
    "    words_no_time_clean = row['words_no_time'].replace(\" \", \"\").replace(\"'\", \"\")\n",
    "    \n",
    "    result_words = []\n",
    "    pointer = 0\n",
    "\n",
    "    for word in transcript_words:\n",
    "        clean_word = word.replace(\"'\", \"\")\n",
    "        temp_pointer = pointer  # Start checking from current position\n",
    "\n",
    "        for char in clean_word:\n",
    "            temp_pointer = words_no_time_clean.find(char, temp_pointer)\n",
    "            if temp_pointer == -1:\n",
    "                break\n",
    "            temp_pointer += 1\n",
    "        else:\n",
    "            # If the entire word matched, update the main pointer and keep the word\n",
    "            pointer = temp_pointer\n",
    "            result_words.append(word)\n",
    "\n",
    "    return \" \".join(result_words)\n",
    "\n",
    "\n",
    "df['transcript_words_intersection'] = df.apply(intersect_words_with_transcript_align, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7981e275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_from_reference_row(row):\n",
    "    compressed = row['words_no_time']\n",
    "    reference = row['transcript_no_punct']\n",
    "\n",
    "    compressed_clean = compressed.replace(\" \", \"\").replace(\"'\", \"\")\n",
    "    reference_clean = reference.replace(\" \", \"\").replace(\"'\", \"\")\n",
    "\n",
    "    start_index = reference_clean.find(compressed_clean)\n",
    "    if start_index == -1:\n",
    "        return \"\"\n",
    "\n",
    "    result = []\n",
    "    ref_char_pos = 0\n",
    "    matched_chars = 0\n",
    "\n",
    "    for char in reference:\n",
    "        if char not in {\" \", \"'\"}:\n",
    "            if ref_char_pos >= start_index and matched_chars < len(compressed_clean):\n",
    "                result.append(char)\n",
    "                matched_chars += 1\n",
    "            elif matched_chars > 0 and matched_chars < len(compressed_clean):\n",
    "                result.append(char)\n",
    "            ref_char_pos += 1\n",
    "        elif matched_chars > 0 and matched_chars < len(compressed_clean):\n",
    "            result.append(char)\n",
    "\n",
    "        if matched_chars == len(compressed_clean):\n",
    "            break\n",
    "\n",
    "    return ''.join(result).strip()\n",
    "\n",
    "df['transcript_words_restored'] = df.apply(restore_from_reference_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5aea3d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of disagreeing rows (ignoring whitespace/apostrophes): 162\n"
     ]
    }
   ],
   "source": [
    "def check_non_whitespace_apostrophe_match(row):\n",
    "    a = re.sub(r\"[ '\\t\\n\\r\\f\\v]\", \"\", row['words_no_time'])\n",
    "    b = re.sub(r\"[ '\\t\\n\\r\\f\\v]\", \"\", row['transcript_words_restored'])\n",
    "\n",
    "    return a != b\n",
    "\n",
    "# Apply across the DataFrame\n",
    "disagreements = df.apply(check_non_whitespace_apostrophe_match, axis=1)\n",
    "disagreement_count = disagreements.sum()\n",
    "mismatches = df[disagreements]\n",
    "\n",
    "print(f\"Number of disagreeing rows (ignoring whitespace/apostrophes): {disagreement_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a917ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not currently needed\n",
    "# Used to look at differences exist between lines and words\n",
    "#df[['filename','transcript_no_punct','words_no_time','transcript_words_restored']].iloc[29763]\n",
    "#pd.set_option(\"display.max_rows\", None) \n",
    "#pd.set_option(\"display.max_columns\", None)\n",
    "#pd.set_option(\"display.width\", 0)  # Automatically fit to content width\n",
    "#pd.set_option(\"display.max_colwidth\", None)\n",
    "#pd.set_option(\"display.expand_frame_repr\", False)  # Disable line wrapping for wide frames\n",
    "#mismatches = df[disagreements]\n",
    "#print(mismatches[['filename','transcript_no_punct','words_no_time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbe0bc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_no_punct</th>\n",
       "      <th>words_no_time</th>\n",
       "      <th>transcript_words_restored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>life is a moment in space</td>\n",
       "      <td>life is a moment in space</td>\n",
       "      <td>life is a moment in space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when the dream is gone</td>\n",
       "      <td>thedream is gone</td>\n",
       "      <td>the dream is gone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it's a lonelier place</td>\n",
       "      <td>alonelier</td>\n",
       "      <td>a lonelier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i kiss the morning goodbye</td>\n",
       "      <td>i kiss the morning goodbye</td>\n",
       "      <td>i kiss the morning goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>butdown inside</td>\n",
       "      <td>inside</td>\n",
       "      <td>inside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>you know we never know why</td>\n",
       "      <td>you know we never know why</td>\n",
       "      <td>you know we never know why</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the road is narrow and long</td>\n",
       "      <td>road is narrow and</td>\n",
       "      <td>road is narrow and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>when eyes meet eyes</td>\n",
       "      <td>eyes meet</td>\n",
       "      <td>eyes meet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and the feeling is strong</td>\n",
       "      <td>thefeeling is strong</td>\n",
       "      <td>the feeling is strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i turn away from the wall</td>\n",
       "      <td>i turn away from the wa ll</td>\n",
       "      <td>i turn away from the wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>i stumble and fall</td>\n",
       "      <td>i stumble and fa</td>\n",
       "      <td>i stumble and fa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>but i give you it all</td>\n",
       "      <td>give you it</td>\n",
       "      <td>give you it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>i am a woman in love</td>\n",
       "      <td>am a woman in love</td>\n",
       "      <td>am a woman in love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>and i'd do anything</td>\n",
       "      <td>andid do anything</td>\n",
       "      <td>and i'd do anything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>to get you into my world</td>\n",
       "      <td>to get you into my world</td>\n",
       "      <td>to get you into my world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>and hold you within</td>\n",
       "      <td>and hold you within</td>\n",
       "      <td>and hold you within</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>it's aright i defend</td>\n",
       "      <td>its aright i</td>\n",
       "      <td>it's aright i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>overand overagain</td>\n",
       "      <td>overand overagain</td>\n",
       "      <td>overand overagain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>what do i do</td>\n",
       "      <td>do i do</td>\n",
       "      <td>do i do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>with you eternally mine</td>\n",
       "      <td>you eternally</td>\n",
       "      <td>you eternally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>in love there is</td>\n",
       "      <td>love there</td>\n",
       "      <td>love there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>nomeasure of time</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>they planned it all at the start</td>\n",
       "      <td>they planned it all at the start</td>\n",
       "      <td>they planned it all at the start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>thatyou and i</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>live in each other's heart</td>\n",
       "      <td>live in each others heart</td>\n",
       "      <td>live in each other's heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>we maybe oceans away</td>\n",
       "      <td>maybe oceans</td>\n",
       "      <td>maybe oceans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>you feel my love</td>\n",
       "      <td>feel my love</td>\n",
       "      <td>feel my love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>i hear what you say</td>\n",
       "      <td>i hear what you say</td>\n",
       "      <td>i hear what you say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>no truth is ever a lie</td>\n",
       "      <td>no truth is ever a li</td>\n",
       "      <td>no truth is ever a li</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>i stumble and fall</td>\n",
       "      <td>stumble and fa</td>\n",
       "      <td>stumble and fa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>but i give you it all</td>\n",
       "      <td>give you it</td>\n",
       "      <td>give you it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>i am a woman in love</td>\n",
       "      <td>i am a woman in love</td>\n",
       "      <td>i am a woman in love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>and i'd do anything</td>\n",
       "      <td>andid do anything</td>\n",
       "      <td>and i'd do anything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>to get you into my world</td>\n",
       "      <td>to get you into my world</td>\n",
       "      <td>to get you into my world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>and hold you within</td>\n",
       "      <td>and hold you within</td>\n",
       "      <td>and hold you within</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>it's aright i defend</td>\n",
       "      <td>aright i defend</td>\n",
       "      <td>aright i defend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>overand overagain</td>\n",
       "      <td>overand overagain</td>\n",
       "      <td>overand overagain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>what do i do</td>\n",
       "      <td>do i</td>\n",
       "      <td>do i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>i am a woman in love</td>\n",
       "      <td>am a woman in</td>\n",
       "      <td>am a woman in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>and i'm talkin' to you</td>\n",
       "      <td>talkin to you</td>\n",
       "      <td>talkin' to you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 transcript_no_punct                     words_no_time  \\\n",
       "0          life is a moment in space         life is a moment in space   \n",
       "1             when the dream is gone                  thedream is gone   \n",
       "2              it's a lonelier place                         alonelier   \n",
       "3         i kiss the morning goodbye        i kiss the morning goodbye   \n",
       "4                     butdown inside                            inside   \n",
       "5         you know we never know why        you know we never know why   \n",
       "6        the road is narrow and long                road is narrow and   \n",
       "7                when eyes meet eyes                         eyes meet   \n",
       "8          and the feeling is strong              thefeeling is strong   \n",
       "9          i turn away from the wall        i turn away from the wa ll   \n",
       "10                i stumble and fall                  i stumble and fa   \n",
       "11             but i give you it all                       give you it   \n",
       "12              i am a woman in love                am a woman in love   \n",
       "13               and i'd do anything                 andid do anything   \n",
       "14          to get you into my world          to get you into my world   \n",
       "15               and hold you within               and hold you within   \n",
       "16              it's aright i defend                      its aright i   \n",
       "17                 overand overagain                 overand overagain   \n",
       "18                      what do i do                           do i do   \n",
       "19           with you eternally mine                     you eternally   \n",
       "20                  in love there is                        love there   \n",
       "21                 nomeasure of time                                of   \n",
       "22  they planned it all at the start  they planned it all at the start   \n",
       "23                     thatyou and i                               and   \n",
       "24        live in each other's heart         live in each others heart   \n",
       "25              we maybe oceans away                      maybe oceans   \n",
       "26                  you feel my love                      feel my love   \n",
       "27               i hear what you say               i hear what you say   \n",
       "28            no truth is ever a lie             no truth is ever a li   \n",
       "29                i stumble and fall                    stumble and fa   \n",
       "30             but i give you it all                       give you it   \n",
       "31              i am a woman in love              i am a woman in love   \n",
       "32               and i'd do anything                 andid do anything   \n",
       "33          to get you into my world          to get you into my world   \n",
       "34               and hold you within               and hold you within   \n",
       "35              it's aright i defend                   aright i defend   \n",
       "36                 overand overagain                 overand overagain   \n",
       "37                      what do i do                              do i   \n",
       "38              i am a woman in love                     am a woman in   \n",
       "39            and i'm talkin' to you                     talkin to you   \n",
       "\n",
       "           transcript_words_restored  \n",
       "0          life is a moment in space  \n",
       "1                  the dream is gone  \n",
       "2                         a lonelier  \n",
       "3         i kiss the morning goodbye  \n",
       "4                             inside  \n",
       "5         you know we never know why  \n",
       "6                 road is narrow and  \n",
       "7                          eyes meet  \n",
       "8              the feeling is strong  \n",
       "9          i turn away from the wall  \n",
       "10                  i stumble and fa  \n",
       "11                       give you it  \n",
       "12                am a woman in love  \n",
       "13               and i'd do anything  \n",
       "14          to get you into my world  \n",
       "15               and hold you within  \n",
       "16                     it's aright i  \n",
       "17                 overand overagain  \n",
       "18                           do i do  \n",
       "19                     you eternally  \n",
       "20                        love there  \n",
       "21                                of  \n",
       "22  they planned it all at the start  \n",
       "23                               and  \n",
       "24        live in each other's heart  \n",
       "25                      maybe oceans  \n",
       "26                      feel my love  \n",
       "27               i hear what you say  \n",
       "28             no truth is ever a li  \n",
       "29                    stumble and fa  \n",
       "30                       give you it  \n",
       "31              i am a woman in love  \n",
       "32               and i'd do anything  \n",
       "33          to get you into my world  \n",
       "34               and hold you within  \n",
       "35                   aright i defend  \n",
       "36                 overand overagain  \n",
       "37                              do i  \n",
       "38                     am a woman in  \n",
       "39                    talkin' to you  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option(\"display.max_rows\", None) \n",
    "pd.set_option(\"display.width\", 0)  \n",
    "df[['transcript_no_punct','words_no_time','transcript_words_restored']].head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0078b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is a collection of functions to further clean the dataset later\n",
    "\n",
    "# Check if a string contains non-English characters\n",
    "def is_non_english(line,freq_threshold=3.0, ratio_threshold=0.5):\n",
    "    # Returns True if line has characters outside basic English alphabet and punctuation\n",
    "    if bool(re.search(r\"[^a-zA-Z0-9\\s.,?!'\\\"-]\", line)):\n",
    "        return True\n",
    "    words = [word for word in line.split()]\n",
    "    if not words:\n",
    "        return False  # Don't flag empty or punctuation-only lines\n",
    "\n",
    "    englishish = [zipf_frequency(word, 'en') >= freq_threshold for word in words]\n",
    "    english_ratio = sum(englishish) / len(englishish)\n",
    "\n",
    "    return english_ratio < ratio_threshold\n",
    "\n",
    "# Check if a string contains the same character 3 or more times in a row\n",
    "def three_or_more_repeats(text):\n",
    "    return bool(re.search(r\"(.)\\1{2,}\", text))\n",
    "\n",
    "# Collapse 3+ letters to 2\n",
    "def collapse_repeats(text):\n",
    "    return re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "\n",
    "# Further collapse certain words from 1 repeat to 0 repeats\n",
    "def collapse_known_repeats(text):\n",
    "    known_patterns = {\"noo\", \"whoo\", \"ohh\", \"yess\", \"goo\", \"aah\", \"woahh\", \"laa\", \"poww\", \"hii\", \"heyy\", \"ayy\", \"okay\", \"byee\"}    \n",
    "    \n",
    "    def collapse(word):\n",
    "            if word in known_patterns:\n",
    "                # Collapse all double letters in the word down to one occurrence\n",
    "                word = re.sub(r'(.)\\1+', r'\\1', word)\n",
    "            return word\n",
    "\n",
    "    return ' '.join(collapse(word) for word in text.split())\n",
    "\n",
    "\n",
    "d = enchant.Dict(\"en_US\")\n",
    "spell = SpellChecker()\n",
    "\n",
    "def is_dictionary_word(word):\n",
    "    if word in {'a','i'}:\n",
    "        return True\n",
    "    if len(word)>1:\n",
    "        if d.check(word):\n",
    "            return True\n",
    "        # spell allows for \"words\" like \"ni\", \"th\", etc...\n",
    "        #if word in spell:\n",
    "            #return True\n",
    "    return False\n",
    "\n",
    "def is_name(word):\n",
    "    if (df_names['name'].str.lower() == word).any():\n",
    "        #print('is a name')\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# For a given nonword, break it into 2+ pieces to see if those pieces are words\n",
    "def split_and_check(word):\n",
    "    length = len(word)\n",
    "\n",
    "    for num_pieces in range(2, 6): # range(2, 4)\n",
    "        # Generate all possible split positions for num_pieces\n",
    "        for split_points in combinations(range(1, length), num_pieces - 1):\n",
    "            indices = (0,) + split_points + (length,)\n",
    "            pieces = [word[indices[i]:indices[i + 1]] for i in range(len(indices) - 1)]\n",
    "\n",
    "            if all(is_dictionary_word(piece) for piece in pieces):\n",
    "                if num_pieces >= 4:\n",
    "                    print('found a',num_pieces, 'parter:',word,pieces)\n",
    "                return pieces\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def maybe_is_a_word(word):\n",
    "    pass\n",
    "    # make use of zipf_frequency here\n",
    "\n",
    "# Used for output formatting\n",
    "def add_quotes(word):\n",
    "    return f'\"{word}\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77abbb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found more than one match for \"yay\" so no action taken.\n"
     ]
    }
   ],
   "source": [
    "# Correct misspellings based on spell checker and phonetics checker\n",
    "dmeta = fuzzy.DMetaphone()\n",
    "\n",
    "def correct_misspelling(misspelled_word):\n",
    "    goal_phonetics = dmeta(misspelled_word)\n",
    "    matches = []\n",
    "    for word in spell.candidates(misspelled_word):\n",
    "        if dmeta(word) == goal_phonetics:\n",
    "            matches.append(word)\n",
    "    if len(matches) == 0:\n",
    "        print(misspelled_word,\"is likely misspelled, but couldn't find a match!\")\n",
    "    if len(matches) == 1:\n",
    "        print(\"Found one match:\",add_quotes(misspelled_word),\"corrects to\",add_quotes(matches[0]))\n",
    "    if len(matches) > 1:\n",
    "        print(\"Found more than one match for\",add_quotes(misspelled_word),\"so no action taken.\")\n",
    "\n",
    "correct_misspelling(\"yay\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a10ce7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False False\n"
     ]
    }
   ],
   "source": [
    "# Perform all 3 word checks to see which the word passes\n",
    "word = 'll'\n",
    "print(d.check(word), word in spell, (df_names['name'].str.lower() == word).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea3e1f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Not found.\n"
     ]
    }
   ],
   "source": [
    "# Check if something is a name, and if so, find its index\n",
    "word = 'ant'\n",
    "print(is_name('ant'))\n",
    "\n",
    "matches = df_names['name'].str.lower() == word.lower()\n",
    "\n",
    "if matches.any():\n",
    "    index = matches.idxmax()  # Returns the first True index\n",
    "    print(f\"Found at index: {index}\")\n",
    "else:\n",
    "    print(\"Not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5590a47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jared\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the tokenizer\n",
    "model_name = \"openai/whisper-base\"\n",
    "language = \"english\" # Change to your dataset's language\n",
    "task = \"transcribe\" # Use \"translate\" if you're translating to English\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(model_name, language=language, task=task)\n",
    "tokenizer = processor.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a75f8077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does zipf_frequency do?\n",
    "zipf_frequency(\"im\", lang=\"en\")\n",
    "\n",
    "def is_known_word(word, threshold=4.0):\n",
    "    return zipf_frequency(word, 'en') >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43afff93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dy', 'ou']\n"
     ]
    }
   ],
   "source": [
    "# Test how a word is tokenized here\n",
    "word = 'dyou'\n",
    "tokens = tokenizer.tokenize(word)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc63b04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Test if things are words here\n",
    "word = \"darling\"\n",
    "print(is_dictionary_word(word))\n",
    "\n",
    "name = 'francisco'\n",
    "print(is_name(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a601ec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a 4 parter: endeavour ['en', 'de', 'av', 'our']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadadoo ['dada', 'dad', 'ad', 'oo']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadadoo ['dada', 'dad', 'ad', 'oo']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadadoo ['dada', 'dad', 'ad', 'oo']\n",
      "found a 4 parter: siberian ['sib', 'er', 'i', 'an']\n",
      "found a 5 parter: transiberian ['trans', 'ib', 'er', 'i', 'an']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadadoo ['dada', 'dad', 'ad', 'oo']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadadoo ['dada', 'dad', 'ad', 'oo']\n",
      "found a 5 parter: toobigforhisbed ['too', 'big', 'for', 'his', 'bed']\n",
      "found a 4 parter: oseraindrops ['os', 'er', 'ain', 'drops']\n",
      "found a 5 parter: evilohouhohuh ['evil', 'oho', 'uh', 'oh', 'uh']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: acchroches ['ac', 'ch', 'roc', 'hes']\n",
      "found a 4 parter: acchroches ['ac', 'ch', 'roc', 'hes']\n",
      "found a 4 parter: acchroches ['ac', 'ch', 'roc', 'hes']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: practised ['pr', 'act', 'is', 'ed']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: shamandalie ['sham', 'and', 'a', 'lie']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: itcomestothe ['it', 'comes', 'to', 'the']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 5 parter: tommermaend ['to', 'mm', 'er', 'ma', 'end']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 5 parter: neimanmarcus ['ne', 'i', 'man', 'marc', 'us']\n",
      "found a 4 parter: sonofagun ['so', 'no', 'fa', 'gun']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: cherches ['ch', 'er', 'ch', 'es']\n",
      "found a 4 parter: nuumbers ['nu', 'um', 'be', 'rs']\n",
      "found a 5 parter: ohohohohoh ['oh', 'oh', 'oh', 'oh', 'oh']\n",
      "found a 4 parter: panthalassa ['pant', 'ha', 'lass', 'a']\n",
      "found a 5 parter: nemitoonam ['ne', 'mi', 'to', 'on', 'am']\n",
      "found a 5 parter: divoonatam ['di', 'vo', 'on', 'a', 'tam']\n",
      "found a 5 parter: nemidooni ['ne', 'mi', 'do', 'on', 'i']\n",
      "found a 4 parter: millionaries ['million', 'ar', 'i', 'es']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 5 parter: shadowwheretruemeaninglies ['shadow', 'where', 'true', 'meaning', 'lies']\n",
      "found a 5 parter: bidilidibi ['bi', 'di', 'li', 'di', 'bi']\n",
      "found a 5 parter: budibupdibu ['bu', 'dib', 'up', 'di', 'bu']\n",
      "found a 4 parter: bubllbubu ['bub', 'll', 'bu', 'bu']\n",
      "found a 4 parter: momories ['mom', 'or', 'i', 'es']\n",
      "found a 4 parter: rumadaidai ['rum', 'ad', 'aid', 'ai']\n",
      "found a 4 parter: rumadaidai ['rum', 'ad', 'aid', 'ai']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: petridish ['pe', 'tr', 'i', 'dish']\n",
      "found a 4 parter: shackabadoo ['shack', 'a', 'bad', 'oo']\n",
      "found a 4 parter: atentionsee ['a', 'tent', 'ion', 'see']\n",
      "found a 5 parter: fahrenheit ['fa', 'hr', 'en', 'he', 'it']\n",
      "found a 5 parter: aprilsnow ['a', 'pr', 'i', 'ls', 'now']\n",
      "found a 4 parter: knowiwantit ['know', 'i', 'wan', 'tit']\n",
      "found a 4 parter: knowiwantit ['know', 'i', 'wan', 'tit']\n",
      "found a 4 parter: wanttofeelyou ['want', 'to', 'feel', 'you']\n",
      "found a 4 parter: needtohearyou ['need', 'to', 'hear', 'you']\n",
      "found a 4 parter: thatkeepsmetrusting ['that', 'keeps', 'me', 'trusting']\n",
      "found a 5 parter: andnotbemovedby ['and', 'not', 'be', 'moved', 'by']\n",
      "found a 4 parter: andyougiveme ['and', 'you', 'give', 'me']\n",
      "found a 4 parter: holdmeinyourhands ['hold', 'meiny', 'our', 'hands']\n",
      "found a 4 parter: youwon'tletme ['you', \"won't\", 'let', 'me']\n",
      "found a 5 parter: youtakemybreathaway ['you', 'take', 'my', 'breath', 'away']\n",
      "found a 4 parter: youtakemein ['you', 'take', 'me', 'in']\n",
      "found a 4 parter: lovethisstrongnever ['love', 'this', 'strong', 'never']\n",
      "found a 4 parter: lovethisstrongnever ['love', 'this', 'strong', 'never']\n",
      "found a 4 parter: gotmelongago ['got', 'me', 'long', 'ago']\n",
      "found a 4 parter: someonemis ['som', 'eon', 'em', 'is']\n",
      "found a 4 parter: toknowyouloved ['to', 'know', 'you', 'loved']\n",
      "found a 4 parter: someonemis ['som', 'eon', 'em', 'is']\n",
      "found a 4 parter: whatyoudoto ['what', 'yo', 'udo', 'to']\n",
      "found a 4 parter: deepandcryout ['deep', 'and', 'cry', 'out']\n",
      "found a 4 parter: someonemis ['som', 'eon', 'em', 'is']\n",
      "found a 4 parter: toknowyouloved ['to', 'know', 'you', 'loved']\n",
      "found a 4 parter: someonemis ['som', 'eon', 'em', 'is']\n",
      "found a 4 parter: todreamofyou ['to', 'dream', 'of', 'you']\n",
      "found a 4 parter: toknowyouloved ['to', 'know', 'you', 'loved']\n",
      "found a 4 parter: hummingbiird ['humming', 'bi', 'i', 'rd']\n",
      "found a 4 parter: cigarretes ['cig', 'arr', 'et', 'es']\n",
      "found a 5 parter: faithfaithfaithfaithfaith ['faith', 'faith', 'faith', 'faith', 'faith']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: staanding ['st', 'a', 'an', 'ding']\n",
      "found a 4 parter: cambodia ['cam', 'bod', 'i', 'a']\n",
      "found a 4 parter: cambodia ['cam', 'bod', 'i', 'a']\n",
      "found a 4 parter: desapeart ['de', 'sap', 'ea', 'rt']\n",
      "found a 4 parter: behindcloseddoorsthey ['behind', 'closed', 'doors', 'they']\n",
      "found a 4 parter: behindcloseddoorsthey ['behind', 'closed', 'doors', 'they']\n",
      "found a 4 parter: ohhtime ['oh', 'ht', 'i', 'me']\n",
      "found a 4 parter: novocaine ['no', 'voc', 'ai', 'ne']\n",
      "found a 4 parter: novocaine ['no', 'voc', 'ai', 'ne']\n",
      "found a 4 parter: abacinate ['ab', 'ac', 'in', 'ate']\n",
      "found a 4 parter: woahmona ['wo', 'ah', 'mon', 'a']\n",
      "found a 4 parter: practising ['pr', 'ac', 'ti', 'sing']\n",
      "found a 5 parter: obsoliation ['ob', 'so', 'li', 'at', 'ion']\n",
      "found a 5 parter: obsoliation ['ob', 'so', 'li', 'at', 'ion']\n",
      "found a 4 parter: umandela ['um', 'an', 'de', 'la']\n",
      "found a 4 parter: umandela ['um', 'an', 'de', 'la']\n",
      "found a 4 parter: umandela ['um', 'an', 'de', 'la']\n",
      "found a 4 parter: umandela ['um', 'an', 'de', 'la']\n",
      "found a 4 parter: umandela ['um', 'an', 'de', 'la']\n",
      "found a 4 parter: siyakhona ['si', 'yak', 'hon', 'a']\n",
      "found a 4 parter: siyakhona ['si', 'yak', 'hon', 'a']\n",
      "found a 4 parter: umandela ['um', 'an', 'de', 'la']\n",
      "found a 4 parter: umandela ['um', 'an', 'de', 'la']\n",
      "found a 4 parter: umandela ['um', 'an', 'de', 'la']\n",
      "found a 4 parter: umandela ['um', 'an', 'de', 'la']\n",
      "found a 4 parter: hadtotella ['had', 'to', 'tel', 'la']\n",
      "found a 4 parter: amancouldbe ['a', 'man', 'could', 'be']\n",
      "found a 4 parter: opression ['op', 're', 'ss', 'ion']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: minnesota ['min', 'ne', 'so', 'ta']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: elvistears ['el', 'vi', 'st', 'ears']\n",
      "found a 4 parter: elvistears ['el', 'vi', 'st', 'ears']\n",
      "found a 5 parter: jagermeister ['ja', 'ger', 'me', 'i', 'ster']\n",
      "found a 4 parter: guardiaan ['guar', 'di', 'a', 'an']\n",
      "found a 4 parter: guardiaan ['guar', 'di', 'a', 'an']\n",
      "found a 4 parter: unmanageables ['unman', 'age', 'abl', 'es']\n",
      "found a 4 parter: guardiaan ['guar', 'di', 'a', 'an']\n",
      "found a 5 parter: halalalalalala ['halal', 'al', 'al', 'al', 'ala']\n",
      "found a 5 parter: halalalalalala ['halal', 'al', 'al', 'al', 'ala']\n",
      "found a 5 parter: halalalalalala ['halal', 'al', 'al', 'al', 'ala']\n",
      "found a 5 parter: whennobodyelsecanhelp ['when', 'nobody', 'else', 'can', 'help']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 5 parter: mysterioous ['my', 'ster', 'i', 'oo', 'us']\n",
      "found a 4 parter: serengeti ['ser', 'en', 'get', 'i']\n",
      "found a 4 parter: illinois ['ill', 'i', 'no', 'is']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: bridren ['br', 'i', 'dr', 'en']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 5 parter: americana ['am', 'er', 'i', 'can', 'a']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 5 parter: philadelphia ['phi', 'la', 'del', 'phi', 'a']\n",
      "found a 5 parter: philadelphia ['phi', 'la', 'del', 'phi', 'a']\n",
      "found a 5 parter: philadelphia ['phi', 'la', 'del', 'phi', 'a']\n",
      "found a 5 parter: philadelphia ['phi', 'la', 'del', 'phi', 'a']\n",
      "found a 5 parter: shalalalala ['sh', 'al', 'al', 'al', 'ala']\n",
      "found a 5 parter: ameerica ['a', 'me', 'er', 'i', 'ca']\n",
      "found a 5 parter: shalalalala ['sh', 'al', 'al', 'al', 'ala']\n",
      "found a 5 parter: shalalalala ['sh', 'al', 'al', 'al', 'ala']\n",
      "found a 4 parter: willyoutieit ['will', 'you', 'tie', 'it']\n",
      "found a 4 parter: desolaation ['de', 'sola', 'at', 'ion']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 4 parter: ashidori ['as', 'hi', 'dor', 'i']\n",
      "found a 4 parter: isogaseta ['i', 'so', 'gas', 'eta']\n",
      "found a 5 parter: omoidashita ['om', 'oi', 'dash', 'i', 'ta']\n",
      "found a 4 parter: hajimarun ['haj', 'i', 'ma', 'run']\n",
      "found a 4 parter: ilovethepain ['i', 'love', 'the', 'pain']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 5 parter: ddanddara ['dd', 'an', 'dd', 'ar', 'a']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: dominatus ['do', 'min', 'at', 'us']\n",
      "found a 4 parter: thingsain'trightgirl ['things', \"ain't\", 'right', 'girl']\n",
      "found a 4 parter: earswon'tstopringing ['ears', \"won't\", 'stop', 'ringing']\n",
      "found a 4 parter: shania ['sh', 'an', 'i', 'a']\n",
      "found a 4 parter: dakishimete ['dak', 'is', 'hi', 'mete']\n",
      "found a 4 parter: dakishimete ['dak', 'is', 'hi', 'mete']\n",
      "found a 5 parter: tsutaetai ['ts', 'ut', 'a', 'et', 'ai']\n",
      "found a 4 parter: dracula ['dr', 'a', 'cu', 'la']\n",
      "found a 4 parter: sonofagun ['so', 'no', 'fa', 'gun']\n",
      "found a 4 parter: woahwoah ['wo', 'ah', 'wo', 'ah']\n",
      "found a 4 parter: dominicana ['do', 'mini', 'can', 'a']\n",
      "found a 4 parter: ferricadooza ['ferric', 'ado', 'oz', 'a']\n",
      "found a 4 parter: americans ['am', 'er', 'i', 'cans']\n",
      "found a 4 parter: americans ['am', 'er', 'i', 'cans']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: hypnotised ['hyp', 'not', 'is', 'ed']\n",
      "found a 4 parter: it'sbeenrumoredthat [\"it's\", 'been', 'rumored', 'that']\n",
      "found a 4 parter: mytearsdryon ['my', 'tears', 'dr', 'yon']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: cheshma ['ch', 'es', 'hm', 'a']\n",
      "found a 4 parter: hoovsies ['hoo', 'vs', 'i', 'es']\n",
      "found a 5 parter: mysterioous ['my', 'ster', 'i', 'oo', 'us']\n",
      "found a 4 parter: dedecateboy ['de', 'de', 'cate', 'boy']\n",
      "found a 4 parter: youshinethelight ['you', 'shine', 'the', 'light']\n",
      "found a 4 parter: youmakethewhole ['you', 'make', 'the', 'whole']\n",
      "found a 5 parter: thelightonhiddenparts ['the', 'light', 'on', 'hidden', 'parts']\n",
      "found a 4 parter: inthehystericalrealm ['in', 'the', 'hysterical', 'realm']\n",
      "found a 4 parter: stupide ['st', 'up', 'i', 'de']\n",
      "found a 4 parter: hahahahahaa ['hah', 'aha', 'hah', 'aa']\n",
      "found a 4 parter: hahahahahaa ['hah', 'aha', 'hah', 'aa']\n",
      "found a 4 parter: quelched ['qu', 'el', 'ch', 'ed']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: youterterit's ['you', 'ter', 'ter', \"it's\"]\n",
      "found a 4 parter: alrealaugh ['al', 're', 'a', 'laugh']\n",
      "found a 4 parter: that'snowaytago [\"that's\", 'noway', 'ta', 'go']\n",
      "found a 4 parter: understooding ['under', 'st', 'oo', 'ding']\n",
      "found a 4 parter: ledietal ['led', 'i', 'et', 'al']\n",
      "found a 4 parter: ledietal ['led', 'i', 'et', 'al']\n",
      "found a 5 parter: neimanmarcus ['ne', 'i', 'man', 'marc', 'us']\n",
      "found a 4 parter: balarama ['bal', 'a', 'ram', 'a']\n",
      "found a 5 parter: momomomomore ['mo', 'mo', 'mo', 'mo', 'more']\n",
      "found a 5 parter: momomomomore ['mo', 'mo', 'mo', 'mo', 'more']\n",
      "found a 4 parter: acrowdcouldever ['a', 'crowd', 'could', 'ever']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: itsthoughtslikethis ['its', 'thoughts', 'like', 'this']\n",
      "found a 4 parter: goohohoh ['go', 'oh', 'oh', 'oh']\n",
      "found a 4 parter: woahwoah ['wo', 'ah', 'wo', 'ah']\n",
      "found a 4 parter: woahwoah ['wo', 'ah', 'wo', 'ah']\n",
      "found a 4 parter: blackned ['bl', 'ac', 'kn', 'ed']\n",
      "found a 5 parter: someindonesian ['some', 'in', 'done', 'si', 'an']\n",
      "found a 5 parter: neimanmarcus ['ne', 'i', 'man', 'marc', 'us']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: woahohoh ['wo', 'ah', 'oh', 'oh']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: stiings ['st', 'i', 'in', 'gs']\n",
      "found a 4 parter: stiings ['st', 'i', 'in', 'gs']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: sonofagun ['so', 'no', 'fa', 'gun']\n",
      "found a 4 parter: explaiin ['ex', 'pl', 'ai', 'in']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: taipei ['ta', 'i', 'pe', 'i']\n",
      "found a 4 parter: memorised ['mem', 'or', 'is', 'ed']\n",
      "found a 4 parter: memorised ['mem', 'or', 'is', 'ed']\n",
      "found a 5 parter: thesewingsweremadeto ['these', 'wings', 'we', 'remade', 'to']\n",
      "found a 5 parter: thesewingsweremadeto ['these', 'wings', 'we', 'remade', 'to']\n",
      "found a 5 parter: thesewingsweremadeto ['these', 'wings', 'we', 'remade', 'to']\n",
      "found a 5 parter: thesewingsweremadeto ['these', 'wings', 'we', 'remade', 'to']\n",
      "found a 4 parter: thesewingsweremade ['these', 'wings', 'we', 'remade']\n",
      "found a 5 parter: thesewingsweremadeto ['these', 'wings', 'we', 'remade', 'to']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 5 parter: lalalalala ['la', 'la', 'la', 'la', 'la']\n",
      "found a 5 parter: lalalalala ['la', 'la', 'la', 'la', 'la']\n",
      "found a 5 parter: lalalalala ['la', 'la', 'la', 'la', 'la']\n",
      "found a 5 parter: lalalalala ['la', 'la', 'la', 'la', 'la']\n",
      "found a 5 parter: lalalalala ['la', 'la', 'la', 'la', 'la']\n",
      "found a 5 parter: lalalalala ['la', 'la', 'la', 'la', 'la']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: histeria ['hi', 'ster', 'i', 'a']\n",
      "found a 4 parter: ifisaidsome ['if', 'i', 'said', 'some']\n",
      "found a 4 parter: youdon'tknownot ['you', \"don't\", 'know', 'not']\n",
      "found a 5 parter: boutthedreamsihave ['bout', 'the', 'dream', 'si', 'have']\n",
      "found a 5 parter: iwillmakeyousleep ['i', 'will', 'make', 'you', 'sleep']\n",
      "found a 4 parter: youdon'tknownot ['you', \"don't\", 'know', 'not']\n",
      "found a 5 parter: youwillbethemis ['you', 'will', 'be', 'them', 'is']\n",
      "found a 4 parter: youwillbegi ['you', 'will', 'be', 'gi']\n",
      "found a 4 parter: ifisaidsome ['if', 'i', 'said', 'some']\n",
      "found a 5 parter: youwouldtakethosewords ['you', 'would', 'take', 'those', 'words']\n",
      "found a 5 parter: boutthedreamsihave ['bout', 'the', 'dream', 'si', 'have']\n",
      "found a 5 parter: boutthedreamsihave ['bout', 'the', 'dream', 'si', 'have']\n",
      "found a 5 parter: iwillmakeyousleep ['i', 'will', 'make', 'you', 'sleep']\n",
      "found a 5 parter: boutthedreamsihave ['bout', 'the', 'dream', 'si', 'have']\n",
      "found a 4 parter: bethlehem ['bet', 'hl', 'eh', 'em']\n",
      "found a 5 parter: bequickquickquickquick ['be', 'quick', 'quick', 'quick', 'quick']\n",
      "found a 5 parter: wohohohoho ['wo', 'ho', 'ho', 'ho', 'ho']\n",
      "found a 5 parter: wohohohoho ['wo', 'ho', 'ho', 'ho', 'ho']\n",
      "found a 4 parter: bethlehem ['bet', 'hl', 'eh', 'em']\n",
      "found a 4 parter: bethlehem ['bet', 'hl', 'eh', 'em']\n",
      "found a 5 parter: beththlehem ['bet', 'ht', 'hl', 'eh', 'em']\n",
      "found a 4 parter: bethlehem ['bet', 'hl', 'eh', 'em']\n",
      "found a 4 parter: bethlehem ['bet', 'hl', 'eh', 'em']\n",
      "found a 4 parter: bethlehem ['bet', 'hl', 'eh', 'em']\n",
      "found a 4 parter: bethlehem ['bet', 'hl', 'eh', 'em']\n",
      "found a 4 parter: choochoo ['ch', 'oo', 'ch', 'oo']\n",
      "found a 4 parter: goodbyeyeyeye ['goodby', 'eye', 'ye', 'ye']\n",
      "found a 5 parter: shenandoah ['sh', 'en', 'an', 'do', 'ah']\n",
      "found a 4 parter: chiquitita ['chi', 'quit', 'i', 'ta']\n",
      "found a 4 parter: chiquitita ['chi', 'quit', 'i', 'ta']\n",
      "found a 4 parter: chiquitita ['chi', 'quit', 'i', 'ta']\n",
      "found a 4 parter: chiquitita ['chi', 'quit', 'i', 'ta']\n",
      "found a 4 parter: chiquitita ['chi', 'quit', 'i', 'ta']\n",
      "found a 4 parter: chiquitita ['chi', 'quit', 'i', 'ta']\n",
      "found a 4 parter: moutains ['mo', 'ut', 'a', 'ins']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: memorised ['mem', 'or', 'is', 'ed']\n",
      "found a 4 parter: partisian ['par', 'ti', 'si', 'an']\n",
      "found a 4 parter: gravitats ['gr', 'a', 'vi', 'tats']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: bananular ['ban', 'a', 'nu', 'lar']\n",
      "found a 5 parter: boobadoobadoop ['boob', 'ado', 'ob', 'ado', 'op']\n",
      "found a 4 parter: bananular ['ban', 'a', 'nu', 'lar']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: taipei ['ta', 'i', 'pe', 'i']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: isawyouwalk ['i', 'saw', 'you', 'walk']\n",
      "found a 5 parter: makehermineallmine ['make', 'her', 'mine', 'all', 'mine']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 5 parter: youturnandwalka ['you', 'turn', 'and', 'walk', 'a']\n",
      "found a 5 parter: wheniwantosay ['when', 'i', 'wan', 'to', 'say']\n",
      "found a 4 parter: givemeyourword ['give', 'me', 'your', 'word']\n",
      "found a 5 parter: youturnandwalka ['you', 'turn', 'and', 'walk', 'a']\n",
      "found a 5 parter: wheniwantosay ['when', 'i', 'wan', 'to', 'say']\n",
      "found a 4 parter: givemeyourword ['give', 'me', 'your', 'word']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: doncamatic ['don', 'ca', 'ma', 'tic']\n",
      "found a 5 parter: incapaciate ['in', 'cap', 'ac', 'i', 'ate']\n",
      "found a 4 parter: sensimilla ['sen', 'si', 'mil', 'la']\n",
      "found a 4 parter: shangri ['sh', 'an', 'gr', 'i']\n",
      "found a 4 parter: obliviion ['ob', 'li', 'vi', 'ion']\n",
      "found a 4 parter: dedededid ['de', 'de', 'de', 'did']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 5 parter: sceneries ['sc', 'en', 'er', 'i', 'es']\n",
      "found a 5 parter: thatwhenyoufeelyou've ['that', 'when', 'you', 'feel', \"you've\"]\n",
      "found a 5 parter: ahahahahahahah ['ah', 'aha', 'hah', 'aha', 'hah']\n",
      "found a 5 parter: philadelphia ['phi', 'la', 'del', 'phi', 'a']\n",
      "found a 4 parter: papperlapap ['pap', 'per', 'la', 'pap']\n",
      "found a 4 parter: papperlapap ['pap', 'per', 'la', 'pap']\n",
      "found a 4 parter: hypnotised ['hyp', 'not', 'is', 'ed']\n",
      "found a 4 parter: choochoo ['ch', 'oo', 'ch', 'oo']\n",
      "found a 5 parter: nonononono ['no', 'no', 'no', 'no', 'no']\n",
      "found a 4 parter: nononono ['no', 'no', 'no', 'no']\n",
      "found a 5 parter: fahrenheit ['fa', 'hr', 'en', 'he', 'it']\n",
      "found a 5 parter: fahrenheit ['fa', 'hr', 'en', 'he', 'it']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: beacusea ['be', 'a', 'cu', 'sea']\n"
     ]
    }
   ],
   "source": [
    "# count WER score of interest\n",
    "count=0\n",
    "# count the number of occurrences of 3+ consecutive letters\n",
    "transcript_count=0\n",
    "# count the number of non-English character occurences\n",
    "nonenglish_count=0\n",
    "\n",
    "for i in range(len(df.words)):  #len(df.words)\n",
    "\n",
    "    result = []\n",
    "    collapsed_transcript_list = []\n",
    "    split_transcript_list = []\n",
    "    tokenized_transcript = []\n",
    "    tokenized_result = []\n",
    "\n",
    "    # pull the original line transcript and get rid of junk repeat letters like woooooo\n",
    "    transcript = df.transcript_no_punct[i]\n",
    "    transcript = collapse_repeats(transcript)\n",
    "    transcript = collapse_known_repeats(transcript)\n",
    "\n",
    "    # collapse repeat letters in the transcript\n",
    "    transcript_list = transcript.split(\" \")\n",
    "    for word in transcript_list:\n",
    "        collapsed_transcript_list.append(collapse_repeats(word))\n",
    "\n",
    "    transcript_list = collapsed_transcript_list\n",
    "\n",
    "    # break up incorrect compound words in the transcript\n",
    "    for word in transcript_list:\n",
    "        if not is_dictionary_word(word):\n",
    "            if not is_name(word):\n",
    "                split_attempt = split_and_check(word)\n",
    "                if split_attempt is False:\n",
    "                    split_transcript_list.append(word)\n",
    "                else:\n",
    "                    #print('we found a split! originally:',word)\n",
    "                    split_transcript_list.append(\" \".join(split_attempt))\n",
    "\n",
    "    transcript_list = split_transcript_list\n",
    "\n",
    "    # tokenize the transcript\n",
    "    for word in transcript_list:\n",
    "        token = tokenizer.tokenize(word)\n",
    "        tokenized_transcript.append(token)\n",
    "\n",
    "    transcript = \" \".join(transcript_list)\n",
    "    # check if transcript contains non-English words and chars\n",
    "    status = is_non_english(transcript)\n",
    "    if status:\n",
    "        #print(transcript, df.filename[i])\n",
    "        nonenglish_count += status\n",
    "\n",
    "    # loop over words to append them one at a time to result\n",
    "    for obj in df.words[i]:                \n",
    "        result.append(obj['word'])\n",
    "        token = tokenizer.tokenize(obj['word'])\n",
    "        tokenized_result.append(token)\n",
    "    line = \" \".join(result)\n",
    "    \n",
    "    # compute WER to assess quality of each line\n",
    "    wer_score = jiwer.wer(line, transcript)\n",
    "    if wer_score>.1:\n",
    "        #print(line+',',transcript+',', wer_score)\n",
    "        count += 1\n",
    "\n",
    "    #if status:\n",
    "        #print(\"orig. concat:\",line+',',\"token concat:\", tokenized_result,transcript+',',\"token concat:\",tokenized_transcript, \"WER score:\", wer_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9a5f4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: follow the aeon path\n",
      "Updated:  follow the eon path\n",
      "\n",
      "Original: follow the aeon path\n",
      "Updated:  follow the eon path\n",
      "\n",
      "Original: follow the aeon path\n",
      "Updated:  follow the eon path\n",
      "\n",
      "Original: now let's not analyse --\n",
      "Updated:  now let's not analyze --\n",
      "\n",
      "Original: don't analyse don't analyse\n",
      "Updated:  don't analyze don't analyze\n",
      "\n",
      "Original: don't analyse don't analyse\n",
      "Updated:  don't analyze don't analyze\n",
      "\n",
      "Original: i won't apologise\n",
      "Updated:  i won't apologize\n",
      "\n",
      "Original: and now apologise\n",
      "Updated:  and now apologize\n",
      "\n",
      "Original: i might never be your knight in shining armour\n",
      "Updated:  i might never be your knight in shining armor\n",
      "\n",
      "Original: and you know you where their armour\n",
      "Updated:  and you know you where their armor\n",
      "\n",
      "Original: 'cos i've cancelled the milk\n",
      "Updated:  'cos i've canceled the milk\n",
      "\n",
      "Original: from a-mail-order catalogue,\n",
      "Updated:  from a-mail-order catalog,\n",
      "\n",
      "Original: without the centre of my life\n",
      "Updated:  without the center of my life\n",
      "\n",
      "Original: colour in a rainbow\n",
      "Updated:  color in a rainbow\n",
      "\n",
      "Original: like colour from the face\n",
      "Updated:  like color from the face\n",
      "\n",
      "Original: like colour from the face\n",
      "Updated:  like color from the face\n",
      "\n",
      "Original: to blame the colour tv\n",
      "Updated:  to blame the color tv\n",
      "\n",
      "Original: and now- every mother can choose the colour\n",
      "Updated:  and now- every mother can choose the color\n",
      "\n",
      "Original: it's the colour of his eyes\n",
      "Updated:  it's the color of his eyes\n",
      "\n",
      "Original: is the line on the colour bar\n",
      "Updated:  is the line on the color bar\n",
      "\n",
      "Original: i can't see that i got red hands i'm colour blind sing day-oh.\n",
      "Updated:  i can't see that i got red hands i'm color blind sing day-oh.\n",
      "\n",
      "Original: we are the colour symphony\n",
      "Updated:  we are the color symphony\n",
      "\n",
      "Original: nothing changed except the colour of the blue\n",
      "Updated:  nothing changed except the color of the blue\n",
      "\n",
      "Original: blue is the colour of all that iwear.\n",
      "Updated:  blue is the color of all that iwear.\n",
      "\n",
      "Original: colour my hair\n",
      "Updated:  color my hair\n",
      "\n",
      "Original: colour my hair\n",
      "Updated:  color my hair\n",
      "\n",
      "Original: colour my hair\n",
      "Updated:  color my hair\n",
      "\n",
      "Original: to colour from shadow\n",
      "Updated:  to color from shadow\n",
      "\n",
      "Original: i can feel the colour\n",
      "Updated:  i can feel the color\n",
      "\n",
      "Original: pagan gods die with no defence\n",
      "Updated:  pagan gods die with no defense\n",
      "\n",
      "Original: try to slip past his defence\n",
      "Updated:  try to slip past his defense\n",
      "\n",
      "Original: hill after hill breaking their lines of defence\n",
      "Updated:  hill after hill breaking their lines of defense\n",
      "\n",
      "Original: never, never endeavour\n",
      "Updated:  never, never endeavor\n",
      "\n",
      "Original: i want to exorcise\n",
      "Updated:  i want to exorcize\n",
      "\n",
      "Original: i want to exorcise\n",
      "Updated:  i want to exorcize\n",
      "\n",
      "Original: i want to exorcise\n",
      "Updated:  i want to exorcize\n",
      "\n",
      "Original: to bask in your favour, i will kill the king\n",
      "Updated:  to bask in your favor, i will kill the king\n",
      "\n",
      "Original: to bask in your favour, i will kill the king\n",
      "Updated:  to bask in your favor, i will kill the king\n",
      "\n",
      "Original: i bask in your favour, i have killed the king\n",
      "Updated:  i bask in your favor, i have killed the king\n",
      "\n",
      "Original: was our favourite song\n",
      "Updated:  was our favorite song\n",
      "\n",
      "Original: was our favourite song\n",
      "Updated:  was our favorite song\n",
      "\n",
      "Original: tell me your favourite song\n",
      "Updated:  tell me your favorite song\n",
      "\n",
      "Original: tell me your favourite song\n",
      "Updated:  tell me your favorite song\n",
      "\n",
      "Original: tell me your favourite song\n",
      "Updated:  tell me your favorite song\n",
      "\n",
      "Original: tell me your favourite song\n",
      "Updated:  tell me your favorite song\n",
      "\n",
      "Original: with your favourite finger\n",
      "Updated:  with your favorite finger\n",
      "\n",
      "Original: favourite game\n",
      "Updated:  favorite game\n",
      "\n",
      "Original: losing my favourite game\n",
      "Updated:  losing my favorite game\n",
      "\n",
      "Original: favourite game\n",
      "Updated:  favorite game\n",
      "\n",
      "Original: losing my favourite\n",
      "Updated:  losing my favorite\n",
      "\n",
      "Original: favourite game\n",
      "Updated:  favorite game\n",
      "\n",
      "Original: jambalaya and crawfish pie and fillet gumbo\n",
      "Updated:  jambalaya and crawfish pie and filet gumbo\n",
      "\n",
      "Original: jambalaya-'n crawfish pie and fillet gumbo\n",
      "Updated:  jambalaya-'n crawfish pie and filet gumbo\n",
      "\n",
      "Original: jambalaya-'n crawfish pie and fillet gumbo\n",
      "Updated:  jambalaya-'n crawfish pie and filet gumbo\n",
      "\n",
      "Original: jambalaya-'n crawfish pie and fillet gumbo\n",
      "Updated:  jambalaya-'n crawfish pie and filet gumbo\n",
      "\n",
      "Original: jambalaya-'n crawfish pie and fillet gumbo\n",
      "Updated:  jambalaya-'n crawfish pie and filet gumbo\n",
      "\n",
      "Original: ne-ver ne-ver try to gauge tem-para-ture\n",
      "Updated:  ne-ver ne-ver try to gage tem-para-ture\n",
      "\n",
      "Original: ne-ver ne-ver try to gauge tem-para-ture\n",
      "Updated:  ne-ver ne-ver try to gage tem-para-ture\n",
      "\n",
      "Original: ne-ver ne-ver try to gauge tem-para-ture\n",
      "Updated:  ne-ver ne-ver try to gage tem-para-ture\n",
      "\n",
      "Original: feel the glamour in pink\n",
      "Updated:  feel the glamor in pink\n",
      "\n",
      "Original: she's all dressed up for glamour\n",
      "Updated:  she's all dressed up for glamor\n",
      "\n",
      "Original: will embrace the world in grey,\n",
      "Updated:  will embrace the world in gray,\n",
      "\n",
      "Original: will embrace the world in grey,\n",
      "Updated:  will embrace the world in gray,\n",
      "\n",
      "Original: will embrace the world in grey,\n",
      "Updated:  will embrace the world in gray,\n",
      "\n",
      "Original: will embrace the world in grey,\n",
      "Updated:  will embrace the world in gray,\n",
      "\n",
      "Original: my little grey dove\n",
      "Updated:  my little gray dove\n",
      "\n",
      "Original: for the earth is old and grey\n",
      "Updated:  for the earth is old and gray\n",
      "\n",
      "Original: and even if i could it'd all be grey,\n",
      "Updated:  and even if i could it'd all be gray,\n",
      "\n",
      "Original: and even if i could it'd all be grey,\n",
      "Updated:  and even if i could it'd all be gray,\n",
      "\n",
      "Original: and even if i could it'd all be grey,\n",
      "Updated:  and even if i could it'd all be gray,\n",
      "\n",
      "Original: and even if i could it'd all be grey,\n",
      "Updated:  and even if i could it'd all be gray,\n",
      "\n",
      "Original: on a cold and grey chicago mornin'\n",
      "Updated:  on a cold and gray chicago mornin'\n",
      "\n",
      "Original: on a cold and grey chicago mornin',\n",
      "Updated:  on a cold and gray chicago mornin',\n",
      "\n",
      "Original: a few grey federales say\n",
      "Updated:  a few gray federales say\n",
      "\n",
      "Original: ragged lines of ragged grey\n",
      "Updated:  ragged lines of ragged gray\n",
      "\n",
      "Original: no more them grey skies\n",
      "Updated:  no more them gray skies\n",
      "\n",
      "Original: no more them grey skies\n",
      "Updated:  no more them gray skies\n",
      "\n",
      "Original: no more them grey skies\n",
      "Updated:  no more them gray skies\n",
      "\n",
      "Original: oh the sea is cold and the sky is grey\n",
      "Updated:  oh the sea is cold and the sky is gray\n",
      "\n",
      "Original: on a grey tour bus\n",
      "Updated:  on a gray tour bus\n",
      "\n",
      "Original: grey skies and light fading\n",
      "Updated:  gray skies and light fading\n",
      "\n",
      "Original: watched his hair been turnin' grey\n",
      "Updated:  watched his hair been turnin' gray\n",
      "\n",
      "Original: watched his hair been turnin' grey yeah\n",
      "Updated:  watched his hair been turnin' gray yeah\n",
      "\n",
      "Original: tears - for heroes dressed in grey\n",
      "Updated:  tears - for heroes dressed in gray\n",
      "\n",
      "Original: my days are absolutely grey\n",
      "Updated:  my days are absolutely gray\n",
      "\n",
      "Original: my days are absolutely grey\n",
      "Updated:  my days are absolutely gray\n",
      "\n",
      "Original: these grey stone walls\n",
      "Updated:  these gray stone walls\n",
      "\n",
      "Original: each day as if our lifes are not so grey,\n",
      "Updated:  each day as if our lifes are not so gray,\n",
      "\n",
      "Original: deeper grey, come to form\n",
      "Updated:  deeper gray, come to form\n",
      "\n",
      "Original: dark and grey,\n",
      "Updated:  dark and gray,\n",
      "\n",
      "Original: complexion turns to grey\n",
      "Updated:  complexion turns to gray\n",
      "\n",
      "Original: complexion turns to grey\n",
      "Updated:  complexion turns to gray\n",
      "\n",
      "Original: and skies turned to grey.\n",
      "Updated:  and skies turned to gray.\n",
      "\n",
      "Original: cold and grey\n",
      "Updated:  cold and gray\n",
      "\n",
      "Original: cold and grey\n",
      "Updated:  cold and gray\n",
      "\n",
      "Original: cold and grey\n",
      "Updated:  cold and gray\n",
      "\n",
      "Original: cold and grey\n",
      "Updated:  cold and gray\n",
      "\n",
      "Original: cold and grey\n",
      "Updated:  cold and gray\n",
      "\n",
      "Original: so take your grey poupon my friend\n",
      "Updated:  so take your gray poupon my friend\n",
      "\n",
      "Original: livin' his grey flannel life,\n",
      "Updated:  livin' his gray flannel life,\n",
      "\n",
      "Original: and the sun has turned to grey\n",
      "Updated:  and the sun has turned to gray\n",
      "\n",
      "Original: when i'm grey and older\n",
      "Updated:  when i'm gray and older\n",
      "\n",
      "Original: when the skies are grey\n",
      "Updated:  when the skies are gray\n",
      "\n",
      "Original: cover up the grey\n",
      "Updated:  cover up the gray\n",
      "\n",
      "Original: cover up the grey\n",
      "Updated:  cover up the gray\n",
      "\n",
      "Original: cover up the grey\n",
      "Updated:  cover up the gray\n",
      "\n",
      "Original: headache grey\n",
      "Updated:  headache gray\n",
      "\n",
      "Original: in this grey grey world where nobody sings\n",
      "Updated:  in this gray gray world where nobody sings\n",
      "\n",
      "Original: your heart inside that's grey\n",
      "Updated:  your heart inside that's gray\n",
      "\n",
      "Original: in shades of grey\n",
      "Updated:  in shades of gray\n",
      "\n",
      "Original: now everything's grey\n",
      "Updated:  now everything's gray\n",
      "\n",
      "Original: fade to grey\n",
      "Updated:  fade to gray\n",
      "\n",
      "Original: a harbour in the tempest\n",
      "Updated:  a harbor in the tempest\n",
      "\n",
      "Original: i had a friend from over the harbour\n",
      "Updated:  i had a friend from over the harbor\n",
      "\n",
      "Original: on our lady of the harbour\n",
      "Updated:  on our lady of the harbor\n",
      "\n",
      "Original: et l'humour et l'amour\n",
      "Updated:  et l'humor et l'amour\n",
      "\n",
      "Original: humour me before i have to go\n",
      "Updated:  humor me before i have to go\n",
      "\n",
      "Original: and you hypnotise me\n",
      "Updated:  and you hypnotize me\n",
      "\n",
      "Original: and you hypnotise me\n",
      "Updated:  and you hypnotize me\n",
      "\n",
      "Original: to idolise me\n",
      "Updated:  to idolize me\n",
      "\n",
      "Original: itemise loathing and\n",
      "Updated:  itemize loathing and\n",
      "\n",
      "Original: sit in judgement of all wrong\n",
      "Updated:  sit in judgment of all wrong\n",
      "\n",
      "Original: judgement falls upon you at first light\n",
      "Updated:  judgment falls upon you at first light\n",
      "\n",
      "Original: judgement falls upon you at first light\n",
      "Updated:  judgment falls upon you at first light\n",
      "\n",
      "Original: your judgement's coiled\n",
      "Updated:  your judgment's coiled\n",
      "\n",
      "Original: my judgement's clouded\n",
      "Updated:  my judgment's clouded\n",
      "\n",
      "Original: now we face the judgement day\n",
      "Updated:  now we face the judgment day\n",
      "\n",
      "Original: so the judgement's been made\n",
      "Updated:  so the judgment's been made\n",
      "\n",
      "Original: so the judgement's been made\n",
      "Updated:  so the judgment's been made\n",
      "\n",
      "Original: labour till the work is done\n",
      "Updated:  labor till the work is done\n",
      "\n",
      "Original: labour till the work is done\n",
      "Updated:  labor till the work is done\n",
      "\n",
      "Original: labour till the work is\n",
      "Updated:  labor till the work is\n",
      "\n",
      "Original: labour till the work is done.\n",
      "Updated:  labor till the work is done.\n",
      "\n",
      "Original: and have a picnic on labour days\n",
      "Updated:  and have a picnic on labor days\n",
      "\n",
      "Original: i got a licence for love\n",
      "Updated:  i got a license for love\n",
      "\n",
      "Original: grew a moustache and a mullet\n",
      "Updated:  grew a mustache and a mullet\n",
      "\n",
      "Original: mum's lookin' sad\n",
      "Updated:  mom's lookin' sad\n",
      "\n",
      "Original: mum-do-lafasha\n",
      "Updated:  mom-do-lafasha\n",
      "\n",
      "Original: is it mum and dad?\n",
      "Updated:  is it mom and dad?\n",
      "\n",
      "Original: is it mum and dad?\n",
      "Updated:  is it mom and dad?\n",
      "\n",
      "Original: is it mum and dad?\n",
      "Updated:  is it mom and dad?\n",
      "\n",
      "Original: me and me mum and me dad and me gran\n",
      "Updated:  me and me mom and me dad and me gran\n",
      "\n",
      "Original: me and me mum and me dad and me gran\n",
      "Updated:  me and me mom and me dad and me gran\n",
      "\n",
      "Original: your mum and dad for fools\n",
      "Updated:  your mom and dad for fools\n",
      "\n",
      "Original: oh my mama, mama, oh my mum\n",
      "Updated:  oh my mama, mama, oh my mom\n",
      "\n",
      "Original: oh my mama, mama, oh my mum\n",
      "Updated:  oh my mama, mama, oh my mom\n",
      "\n",
      "Original: substitute. you for my mum.\n",
      "Updated:  substitute. you for my mom.\n",
      "\n",
      "Original: substitute. you for my mum.\n",
      "Updated:  substitute. you for my mom.\n",
      "\n",
      "Original: so, love your neighbour like\n",
      "Updated:  so, love your neighbor like\n",
      "\n",
      "Original: hate your nextdoor neighbour\n",
      "Updated:  hate your nextdoor neighbor\n",
      "\n",
      "Original: they want to make it in the neighbourhood\n",
      "Updated:  they want to make it in the neighborhood\n",
      "\n",
      "Original: they wanna make it in the neighbourhood\n",
      "Updated:  they wanna make it in the neighborhood\n",
      "\n",
      "Original: they want to make it in the neighbourhood\n",
      "Updated:  they want to make it in the neighborhood\n",
      "\n",
      "Original: he said he stayed with a neighbourhood girl\n",
      "Updated:  he said he stayed with a neighborhood girl\n",
      "\n",
      "Original: organise you safe tribal war\n",
      "Updated:  organize you safe tribal war\n",
      "\n",
      "Original: that would paralyse your evolution\n",
      "Updated:  that would paralyze your evolution\n",
      "\n",
      "Original: that would paralyse your evolution\n",
      "Updated:  that would paralyze your evolution\n",
      "\n",
      "Original: it ain't a phoney\n",
      "Updated:  it ain't a phony\n",
      "\n",
      "Original: i'm going back to my plough\n",
      "Updated:  i'm going back to my plow\n",
      "\n",
      "Original: i'm going back to my plough\n",
      "Updated:  i'm going back to my plow\n",
      "\n",
      "Original: i'm practising\n",
      "Updated:  i'm practicing\n",
      "\n",
      "Original: someday i'll wear pyjamas in the daytime\n",
      "Updated:  someday i'll wear pajamas in the daytime\n",
      "\n",
      "Original: someday i'll wear pyjamas in the daytime\n",
      "Updated:  someday i'll wear pajamas in the daytime\n",
      "\n",
      "Original: someday i wear pyjamas in the daytime\n",
      "Updated:  someday i wear pajamas in the daytime\n",
      "\n",
      "Original: i didn't realise iwas talking to the living dead\n",
      "Updated:  i didn't realize iwas talking to the living dead\n",
      "\n",
      "Original: don't you realise the blind lead the blind\n",
      "Updated:  don't you realize the blind lead the blind\n",
      "\n",
      "Original: don't you realise the blind lead the blind\n",
      "Updated:  don't you realize the blind lead the blind\n",
      "\n",
      "Original: to realise that love was in her eyes\n",
      "Updated:  to realize that love was in her eyes\n",
      "\n",
      "Original: i realise i missed a day\n",
      "Updated:  i realize i missed a day\n",
      "\n",
      "Original: she doesn't realise\n",
      "Updated:  she doesn't realize\n",
      "\n",
      "Original: and realise there's nuthin' left\n",
      "Updated:  and realize there's nuthin' left\n",
      "\n",
      "Original: when you gonna realise\n",
      "Updated:  when you gonna realize\n",
      "\n",
      "Original: when you gonna realise\n",
      "Updated:  when you gonna realize\n",
      "\n",
      "Original: when you gonna realise\n",
      "Updated:  when you gonna realize\n",
      "\n",
      "Original: when you gonna realise\n",
      "Updated:  when you gonna realize\n",
      "\n",
      "Original: that's when i realise\n",
      "Updated:  that's when i realize\n",
      "\n",
      "Original: then i realise\n",
      "Updated:  then i realize\n",
      "\n",
      "Original: do you realise\n",
      "Updated:  do you realize\n",
      "\n",
      "Original: do you realise\n",
      "Updated:  do you realize\n",
      "\n",
      "Original: do you realise\n",
      "Updated:  do you realize\n",
      "\n",
      "Original: oh i realise\n",
      "Updated:  oh i realize\n",
      "\n",
      "Original: at what point did you realise\n",
      "Updated:  at what point did you realize\n",
      "\n",
      "Original: then you'll realise\n",
      "Updated:  then you'll realize\n",
      "\n",
      "Original: then you'll realise\n",
      "Updated:  then you'll realize\n",
      "\n",
      "Original: so we can realise the wonder of love\n",
      "Updated:  so we can realize the wonder of love\n",
      "\n",
      "Original: so we can realise the wonder of love\n",
      "Updated:  so we can realize the wonder of love\n",
      "\n",
      "Original: but now i realise that i'm\n",
      "Updated:  but now i realize that i'm\n",
      "\n",
      "Original: and when i look i realise\n",
      "Updated:  and when i look i realize\n",
      "\n",
      "Original: and when i look i realise\n",
      "Updated:  and when i look i realize\n",
      "\n",
      "Original: that i recognise?\n",
      "Updated:  that i recognize?\n",
      "\n",
      "Original: tell me baby, do you recognise me?\n",
      "Updated:  tell me baby, do you recognize me?\n",
      "\n",
      "Original: there's nothing i can recognise;\n",
      "Updated:  there's nothing i can recognize;\n",
      "\n",
      "Original: and recognise your age it's a teenage rampage\n",
      "Updated:  and recognize your age it's a teenage rampage\n",
      "\n",
      "Original: so recognise your age it's a teenage rampage\n",
      "Updated:  so recognize your age it's a teenage rampage\n",
      "\n",
      "Original: and recognise your age it's a teenage rampage\n",
      "Updated:  and recognize your age it's a teenage rampage\n",
      "\n",
      "Original: so recognise your age it's a teenage rampage\n",
      "Updated:  so recognize your age it's a teenage rampage\n",
      "\n",
      "Original: and recognise your age it's a teenage rampage\n",
      "Updated:  and recognize your age it's a teenage rampage\n",
      "\n",
      "Original: so recognise your age it's a teenage rampage\n",
      "Updated:  so recognize your age it's a teenage rampage\n",
      "\n",
      "Original: recognise your age it's a teenage rampage now\n",
      "Updated:  recognize your age it's a teenage rampage now\n",
      "\n",
      "Original: and recognise your age it's a teenage rampage\n",
      "Updated:  and recognize your age it's a teenage rampage\n",
      "\n",
      "Original: sometimes i don't recognise my own face\n",
      "Updated:  sometimes i don't recognize my own face\n",
      "\n",
      "Original: you can't recognise them.\n",
      "Updated:  you can't recognize them.\n",
      "\n",
      "Original: but you can't recognise them.\n",
      "Updated:  but you can't recognize them.\n",
      "\n",
      "Original: and recognise\n",
      "Updated:  and recognize\n",
      "\n",
      "Original: recognise the poison\n",
      "Updated:  recognize the poison\n",
      "\n",
      "Original: there's a rumour goin' round the town\n",
      "Updated:  there's a rumor goin' round the town\n",
      "\n",
      "Original: never thought i'd let a rumour\n",
      "Updated:  never thought i'd let a rumor\n",
      "\n",
      "Original: never thought i'd let a rumour\n",
      "Updated:  never thought i'd let a rumor\n",
      "\n",
      "Original: see the child here as a saviour.\n",
      "Updated:  see the child here as a savior.\n",
      "\n",
      "Original: are you looking for saviour\n",
      "Updated:  are you looking for savior\n",
      "\n",
      "Original: you're losing a saviour\n",
      "Updated:  you're losing a savior\n",
      "\n",
      "Original: saviour of nations\n",
      "Updated:  savior of nations\n",
      "\n",
      "Original: i just saw a saviour\n",
      "Updated:  i just saw a savior\n",
      "\n",
      "Original: a saviour come my way\n",
      "Updated:  a savior come my way\n",
      "\n",
      "Original: this is the night of our dear saviour's birth\n",
      "Updated:  this is the night of our dear savior's birth\n",
      "\n",
      "Original: i'll savour the pause for a while\n",
      "Updated:  i'll savor the pause for a while\n",
      "\n",
      "Original: this sombre song would drain the sun\n",
      "Updated:  this somber song would drain the sun\n",
      "\n",
      "Original: theatre full of sadness\n",
      "Updated:  theater full of sadness\n",
      "\n",
      "Original: would she go down on you in a theatre\n",
      "Updated:  would she go down on you in a theater\n",
      "\n",
      "Original: would she go down on you in a theatre\n",
      "Updated:  would she go down on you in a theater\n",
      "\n",
      "Original: mental vigour's been right on the egde\n",
      "Updated:  mental vigor's been right on the egde\n",
      "\n",
      "Total replacements made: 221\n"
     ]
    }
   ],
   "source": [
    "change_count = 0\n",
    "\n",
    "for _, row in brit_to_us.iterrows():\n",
    "    british_word = row['british']\n",
    "    american_word = row['american']\n",
    "    pattern = r'\\b' + re.escape(british_word) + r'\\b'  # Match whole word\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        original_text = df.loc[i, 'transcript']\n",
    "        updated_text = re.sub(pattern, american_word, original_text)\n",
    "\n",
    "        if original_text != updated_text:\n",
    "            print(f\"Original: {original_text}\")\n",
    "            print(f\"Updated:  {updated_text}\\n\")\n",
    "            df.loc[i, 'transcript'] = updated_text\n",
    "            change_count += 1\n",
    "\n",
    "print(f\"Total replacements made: {change_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
