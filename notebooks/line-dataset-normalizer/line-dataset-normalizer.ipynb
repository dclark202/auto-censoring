{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3ed6aee",
   "metadata": {},
   "source": [
    "### Normalization consists of the following line-by-line process:\n",
    "\n",
    "##### 1. Remove all lines containing nan or non-English characters\n",
    "- For best results, this should happen after transcript is shortened to match with words\n",
    "- Small complication here: before subsequent cleaning, some words don't look like English. Chicken or the egg?\n",
    "\n",
    "##### 2. Collapse 3+ consecutive occurrences of same letter to 2 letters, e.g. moooooo -> moo (timestamps unchanged)\n",
    "- Some words, like hmm, moo, bzz need two consecutive letters\n",
    "- Most words, like fuuck, do not\n",
    "- So after reducing 3+ occurrences to 2, is a dictionary/wordfreq check good enough to say whether an additional letter should be deleted?\n",
    "- Most legit way to do this would be to check how such words are tokenized in Whisper model\n",
    "- woo, oh, no, ah, eyow, go, hm | hmm, \n",
    "- leave lalala alone\n",
    "- change yey to yay\n",
    "\n",
    "##### 3. Check every word to see if it's a word\n",
    "- Might be better to use known dictionary on first pass to get dictionary-standard words before dealing with slang/spelling variants\n",
    "- Backup word test could be passes zipf_frequency test\n",
    "- If not, check if it should be combined with a nearby word fragment(s) to create an actual word, e.g. ci ty -> city. Or a double letter should be changed to a single letter, e.g. \"yees\" -> \"yes\"\n",
    "- Deal with misspellings by combining spell-checker and phonetics-checker\n",
    "\n",
    "\n",
    "### To-Do:\n",
    "\n",
    "##### 1. Combine word chunks and separate illegal compound words\n",
    "- Separated words work pretty good, but they're worsened by the absence of apostrophes like in \"we've\"\n",
    "\n",
    "##### 2. Cut off transcripts at beginning and end if they don't match with words\n",
    "- This should also involve changing audio chunks; will need to write down new start and end times of each chunk\n",
    "- Shortening audio chunks should be automated (with quality/file type preserved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f855f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from wordfreq import zipf_frequency\n",
    "import jiwer\n",
    "import re\n",
    "import numpy as np\n",
    "import enchant\n",
    "from spellchecker import SpellChecker\n",
    "from itertools import combinations\n",
    "from transformers import WhisperProcessor\n",
    "import fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5523002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First and last names used in checking if lyrics are valid words\n",
    "df_male = pd.read_csv('./data/male.txt',header=None,names=[\"name\"])\n",
    "df_female = pd.read_csv('./data/female.txt',header=None,names=[\"name\"])\n",
    "df_last = pd.read_csv('./data/Names_2010Census.csv',usecols = ['name'])\n",
    "\n",
    "df_names = pd.concat([df_male, df_female,df_last], ignore_index=True)\n",
    "\n",
    "# British spellings used to correct spelling later\n",
    "brit_to_us = pd.read_json('./data/british_to_american_sp.json', orient='index')\n",
    "brit_to_us.reset_index(inplace=True)\n",
    "brit_to_us.columns = ['british', 'american']\n",
    "brit_to_us = brit_to_us[~brit_to_us['british'].isin(['aeroplane', 'aluminium', 'buses'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a180b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean metadata-full-lines.csv to have same format as metadata-lines.csv\n",
    "df = pd.read_csv(\"../../data/metadata-full-lines.csv\", usecols=[\"filename\", \"words\", \"transcript\"])\n",
    "df = df.rename(columns={\"words\": \"transcript\", \"transcript\": \"words\"})\n",
    "df = df[[\"filename\", \"words\", \"transcript\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baaaf1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove bad songs (non-English, transcription/lyrics issues, etc.)\n",
    "df_bad = pd.read_csv('./data/bad_songs.csv')\n",
    "df_bad['filename'] = df_bad['filename'].str.replace(r'^\\d+\\.\\s*', '', regex=True)   # remove number + period + spaces at the start\n",
    "df_bad['filename'] = df_bad['filename'].str.replace(r'\\s+', '', regex=True) # delete whitespace\n",
    "\n",
    "# Build a tuple of bad prefixes\n",
    "bad_prefixes = tuple(df_bad['filename'].values)\n",
    "\n",
    "# Filter rows where 'filename' starts with any bad prefix\n",
    "mask = df['filename'].str.startswith(bad_prefixes)\n",
    "\n",
    "df = df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5bc1f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>words</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001940b614eb43f4a0c826d49a67d66d-0.wav</td>\n",
       "      <td>[{'word': 'life', 'start': 0.0, 'end': 0.177},...</td>\n",
       "      <td>life is a moment in space.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001940b614eb43f4a0c826d49a67d66d-1.wav</td>\n",
       "      <td>[{'word': 'thedream', 'start': 0.353, 'end': 0...</td>\n",
       "      <td>when the-dream is gone,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001940b614eb43f4a0c826d49a67d66d-2.wav</td>\n",
       "      <td>[{'word': 'alonelier', 'start': 0.353, 'end': ...</td>\n",
       "      <td>it's a-lonelier place.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001940b614eb43f4a0c826d49a67d66d-3.wav</td>\n",
       "      <td>[{'word': 'i', 'start': 0.0, 'end': 0.177}, {'...</td>\n",
       "      <td>i kiss the morning goodbye,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001940b614eb43f4a0c826d49a67d66d-4.wav</td>\n",
       "      <td>[{'word': 'inside', 'start': 0.353, 'end': 1.4...</td>\n",
       "      <td>butdown inside</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 filename  \\\n",
       "0  001940b614eb43f4a0c826d49a67d66d-0.wav   \n",
       "1  001940b614eb43f4a0c826d49a67d66d-1.wav   \n",
       "2  001940b614eb43f4a0c826d49a67d66d-2.wav   \n",
       "3  001940b614eb43f4a0c826d49a67d66d-3.wav   \n",
       "4  001940b614eb43f4a0c826d49a67d66d-4.wav   \n",
       "\n",
       "                                               words  \\\n",
       "0  [{'word': 'life', 'start': 0.0, 'end': 0.177},...   \n",
       "1  [{'word': 'thedream', 'start': 0.353, 'end': 0...   \n",
       "2  [{'word': 'alonelier', 'start': 0.353, 'end': ...   \n",
       "3  [{'word': 'i', 'start': 0.0, 'end': 0.177}, {'...   \n",
       "4  [{'word': 'inside', 'start': 0.353, 'end': 1.4...   \n",
       "\n",
       "                    transcript  \n",
       "0   life is a moment in space.  \n",
       "1      when the-dream is gone,  \n",
       "2       it's a-lonelier place.  \n",
       "3  i kiss the morning goodbye,  \n",
       "4               butdown inside  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3300fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correctly format all lines (including nan formatting)\n",
    "def parse_and_check_for_nan(val):\n",
    "    if isinstance(val, str):\n",
    "        nan_count = len(re.findall(r\"'word': nan\", val))\n",
    "        if nan_count > 0:\n",
    "            print(f\"'word': nan appears {nan_count} times\")\n",
    "\n",
    "        val_fixed = re.sub(r\"'word': nan\", \"'word': np.nan\", val)\n",
    "        try:\n",
    "            parsed = eval(val_fixed, {\"np\": np})\n",
    "            if any(pd.isna(item.get('word')) for item in parsed):\n",
    "                return None\n",
    "            return parsed\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Format all lines and remove those containing nan\n",
    "df['words'] = df['words'].apply(parse_and_check_for_nan)\n",
    "df = df.dropna(subset=['words']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eaedb9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename                 00d5c65d644c4a549e7d501d65397b7b-3.wav\n",
       "transcript                                     you away with me\n",
       "words         [{'word': 'you', 'start': 0.0, 'end': 0.219}, ...\n",
       "Name: 150, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['filename','transcript','words']].iloc[150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cd6b4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text: delete puctuation (keep apostrophes), collapse multiple spaces\n",
    "df['transcript_no_punct'] = (\n",
    "    df['transcript']\n",
    "    .str.replace(r'(?<=\\S)-(?=\\S)', ' ', regex=True)  # Hyphen surrounded by non-space\n",
    "    .str.replace(r'\\s*-\\s*', '', regex=True) # Hyphen with space on either side\n",
    "    .str.replace(r\"[^\\w\\s'-]\", '', regex=True)  # Remove unwanted punctuation\n",
    "    .str.replace(r\"_\", \"\", regex=True)          # Remove underscores\n",
    "    .str.replace(r\"\\s+\", ' ', regex=True)       # Collapse multiple spaces\n",
    "    .str.strip()\n",
    "    .str.replace(r\"^'+(.*?)'+$\", r\"\\1\", regex=True) # Happens twice to remove outer apostrophes for things like ''you''\n",
    "    .str.replace(r\"^'+(.*?)'+$\", r\"\\1\", regex=True) # See above\n",
    ")\n",
    "\n",
    "# Clean 'words' by deleting duplicate timestamps\n",
    "def remove_duplicate_dicts(lst):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for d in lst:\n",
    "        key = tuple(sorted(d.items()))\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            result.append(d)\n",
    "    return result\n",
    "\n",
    "# Clean 'words' by deleting timestamps which end before they start\n",
    "def remove_invalid_time_dicts(lst):\n",
    "    return [d for d in lst if d.get('end', 0) >= d.get('start', 0)]\n",
    "\n",
    "# Get rid of duplicate and invalid timestamps\n",
    "df['words'] = df['words'].apply(lambda lst: remove_invalid_time_dicts(remove_duplicate_dicts(lst)) if isinstance(lst, list) else lst)\n",
    "\n",
    "# Create column without timestamps\n",
    "df['words_no_time'] = df['words'].apply(lambda lst: \" \".join(item['word'] for item in lst) if isinstance(lst, list) else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb92f380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to further align transcript with words\n",
    "def extract_aligned_words(row):\n",
    "    transcript_words = row['transcript_no_punct'].split()\n",
    "    words_no_time = row['words_no_time'].replace(\" \", \"\").replace(\"'\", \"\")\n",
    "\n",
    "    aligned_words = []\n",
    "    for word in transcript_words:\n",
    "        clean_word = word.replace(\"'\", \"\")\n",
    "        pointer = 0\n",
    "        for char in clean_word:\n",
    "            pointer = words_no_time.find(char, pointer)\n",
    "            if pointer == -1:\n",
    "                break\n",
    "            pointer += 1\n",
    "        else:\n",
    "            aligned_words.append(word)\n",
    "\n",
    "    return \" \".join(aligned_words)\n",
    "\n",
    "df['transcript_words_align'] = df.apply(extract_aligned_words, axis=1)\n",
    "\n",
    "# Used to further align transcript with words\n",
    "def intersect_words_with_transcript_align(row):\n",
    "    transcript_words = row['transcript_words_align'].split()\n",
    "    words_no_time_clean = row['words_no_time'].replace(\" \", \"\").replace(\"'\", \"\")\n",
    "    \n",
    "    result_words = []\n",
    "    pointer = 0\n",
    "\n",
    "    for word in transcript_words:\n",
    "        clean_word = word.replace(\"'\", \"\")\n",
    "        temp_pointer = pointer  # Start checking from current position\n",
    "\n",
    "        for char in clean_word:\n",
    "            temp_pointer = words_no_time_clean.find(char, temp_pointer)\n",
    "            if temp_pointer == -1:\n",
    "                break\n",
    "            temp_pointer += 1\n",
    "        else:\n",
    "            # If the entire word matched, update the main pointer and keep the word\n",
    "            pointer = temp_pointer\n",
    "            result_words.append(word)\n",
    "\n",
    "    return \" \".join(result_words)\n",
    "\n",
    "\n",
    "df['transcript_words_intersection'] = df.apply(intersect_words_with_transcript_align, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7981e275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_from_reference_row(row):\n",
    "    compressed = row['words_no_time']\n",
    "    reference = row['transcript_no_punct']\n",
    "\n",
    "    compressed_clean = compressed.replace(\" \", \"\").replace(\"'\", \"\")\n",
    "    reference_clean = reference.replace(\" \", \"\").replace(\"'\", \"\")\n",
    "\n",
    "    start_index = reference_clean.find(compressed_clean)\n",
    "    if start_index == -1:\n",
    "        return \"\"\n",
    "\n",
    "    result = []\n",
    "    ref_char_pos = 0\n",
    "    matched_chars = 0\n",
    "\n",
    "    for char in reference:\n",
    "        if char not in {\" \", \"'\"}:\n",
    "            if ref_char_pos >= start_index and matched_chars < len(compressed_clean):\n",
    "                result.append(char)\n",
    "                matched_chars += 1\n",
    "            elif matched_chars > 0 and matched_chars < len(compressed_clean):\n",
    "                result.append(char)\n",
    "            ref_char_pos += 1\n",
    "        elif matched_chars > 0 and matched_chars < len(compressed_clean):\n",
    "            result.append(char)\n",
    "\n",
    "        if matched_chars == len(compressed_clean):\n",
    "            break\n",
    "\n",
    "    return ''.join(result).strip()\n",
    "\n",
    "df['transcript_words_restored'] = df.apply(restore_from_reference_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5aea3d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of disagreeing rows (ignoring whitespace/apostrophes): 162\n"
     ]
    }
   ],
   "source": [
    "def check_non_whitespace_apostrophe_match(row):\n",
    "    a = re.sub(r\"[ '\\t\\n\\r\\f\\v]\", \"\", row['words_no_time'])\n",
    "    b = re.sub(r\"[ '\\t\\n\\r\\f\\v]\", \"\", row['transcript_words_restored'])\n",
    "\n",
    "    return a != b\n",
    "\n",
    "# Apply across the DataFrame\n",
    "disagreements = df.apply(check_non_whitespace_apostrophe_match, axis=1)\n",
    "disagreement_count = disagreements.sum()\n",
    "mismatches = df[disagreements]\n",
    "\n",
    "print(f\"Number of disagreeing rows (ignoring whitespace/apostrophes): {disagreement_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a917ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not currently needed\n",
    "# Used to look at differences exist between lines and words\n",
    "#df[['filename','transcript_no_punct','words_no_time','transcript_words_restored']].iloc[29763]\n",
    "#pd.set_option(\"display.max_rows\", None) \n",
    "#pd.set_option(\"display.max_columns\", None)\n",
    "#pd.set_option(\"display.width\", 0)  # Automatically fit to content width\n",
    "#pd.set_option(\"display.max_colwidth\", None)\n",
    "#pd.set_option(\"display.expand_frame_repr\", False)  # Disable line wrapping for wide frames\n",
    "#mismatches = df[disagreements]\n",
    "#print(mismatches[['filename','transcript_no_punct','words_no_time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbe0bc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_no_punct</th>\n",
       "      <th>words_no_time</th>\n",
       "      <th>transcript_words_restored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>life is a moment in space</td>\n",
       "      <td>life is a moment in space</td>\n",
       "      <td>life is a moment in space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when the dream is gone</td>\n",
       "      <td>thedream is gone</td>\n",
       "      <td>the dream is gone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it's a lonelier place</td>\n",
       "      <td>alonelier</td>\n",
       "      <td>a lonelier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i kiss the morning goodbye</td>\n",
       "      <td>i kiss the morning goodbye</td>\n",
       "      <td>i kiss the morning goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>butdown inside</td>\n",
       "      <td>inside</td>\n",
       "      <td>inside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>you know we never know why</td>\n",
       "      <td>you know we never know why</td>\n",
       "      <td>you know we never know why</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the road is narrow and long</td>\n",
       "      <td>road is narrow and</td>\n",
       "      <td>road is narrow and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>when eyes meet eyes</td>\n",
       "      <td>eyes meet</td>\n",
       "      <td>eyes meet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and the feeling is strong</td>\n",
       "      <td>thefeeling is strong</td>\n",
       "      <td>the feeling is strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i turn away from the wall</td>\n",
       "      <td>i turn away from the wa ll</td>\n",
       "      <td>i turn away from the wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>i stumble and fall</td>\n",
       "      <td>i stumble and fa</td>\n",
       "      <td>i stumble and fa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>but i give you it all</td>\n",
       "      <td>give you it</td>\n",
       "      <td>give you it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>i am a woman in love</td>\n",
       "      <td>am a woman in love</td>\n",
       "      <td>am a woman in love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>and i'd do anything</td>\n",
       "      <td>andid do anything</td>\n",
       "      <td>and i'd do anything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>to get you into my world</td>\n",
       "      <td>to get you into my world</td>\n",
       "      <td>to get you into my world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>and hold you within</td>\n",
       "      <td>and hold you within</td>\n",
       "      <td>and hold you within</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>it's aright i defend</td>\n",
       "      <td>its aright i</td>\n",
       "      <td>it's aright i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>overand overagain</td>\n",
       "      <td>overand overagain</td>\n",
       "      <td>overand overagain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>what do i do</td>\n",
       "      <td>do i do</td>\n",
       "      <td>do i do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>with you eternally mine</td>\n",
       "      <td>you eternally</td>\n",
       "      <td>you eternally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>in love there is</td>\n",
       "      <td>love there</td>\n",
       "      <td>love there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>nomeasure of time</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>they planned it all at the start</td>\n",
       "      <td>they planned it all at the start</td>\n",
       "      <td>they planned it all at the start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>thatyou and i</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>live in each other's heart</td>\n",
       "      <td>live in each others heart</td>\n",
       "      <td>live in each other's heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>we maybe oceans away</td>\n",
       "      <td>maybe oceans</td>\n",
       "      <td>maybe oceans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>you feel my love</td>\n",
       "      <td>feel my love</td>\n",
       "      <td>feel my love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>i hear what you say</td>\n",
       "      <td>i hear what you say</td>\n",
       "      <td>i hear what you say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>no truth is ever a lie</td>\n",
       "      <td>no truth is ever a li</td>\n",
       "      <td>no truth is ever a li</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>i stumble and fall</td>\n",
       "      <td>stumble and fa</td>\n",
       "      <td>stumble and fa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>but i give you it all</td>\n",
       "      <td>give you it</td>\n",
       "      <td>give you it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>i am a woman in love</td>\n",
       "      <td>i am a woman in love</td>\n",
       "      <td>i am a woman in love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>and i'd do anything</td>\n",
       "      <td>andid do anything</td>\n",
       "      <td>and i'd do anything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>to get you into my world</td>\n",
       "      <td>to get you into my world</td>\n",
       "      <td>to get you into my world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>and hold you within</td>\n",
       "      <td>and hold you within</td>\n",
       "      <td>and hold you within</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>it's aright i defend</td>\n",
       "      <td>aright i defend</td>\n",
       "      <td>aright i defend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>overand overagain</td>\n",
       "      <td>overand overagain</td>\n",
       "      <td>overand overagain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>what do i do</td>\n",
       "      <td>do i</td>\n",
       "      <td>do i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>i am a woman in love</td>\n",
       "      <td>am a woman in</td>\n",
       "      <td>am a woman in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>and i'm talkin' to you</td>\n",
       "      <td>talkin to you</td>\n",
       "      <td>talkin' to you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 transcript_no_punct                     words_no_time         transcript_words_restored\n",
       "0          life is a moment in space         life is a moment in space         life is a moment in space\n",
       "1             when the dream is gone                  thedream is gone                 the dream is gone\n",
       "2              it's a lonelier place                         alonelier                        a lonelier\n",
       "3         i kiss the morning goodbye        i kiss the morning goodbye        i kiss the morning goodbye\n",
       "4                     butdown inside                            inside                            inside\n",
       "5         you know we never know why        you know we never know why        you know we never know why\n",
       "6        the road is narrow and long                road is narrow and                road is narrow and\n",
       "7                when eyes meet eyes                         eyes meet                         eyes meet\n",
       "8          and the feeling is strong              thefeeling is strong             the feeling is strong\n",
       "9          i turn away from the wall        i turn away from the wa ll         i turn away from the wall\n",
       "10                i stumble and fall                  i stumble and fa                  i stumble and fa\n",
       "11             but i give you it all                       give you it                       give you it\n",
       "12              i am a woman in love                am a woman in love                am a woman in love\n",
       "13               and i'd do anything                 andid do anything               and i'd do anything\n",
       "14          to get you into my world          to get you into my world          to get you into my world\n",
       "15               and hold you within               and hold you within               and hold you within\n",
       "16              it's aright i defend                      its aright i                     it's aright i\n",
       "17                 overand overagain                 overand overagain                 overand overagain\n",
       "18                      what do i do                           do i do                           do i do\n",
       "19           with you eternally mine                     you eternally                     you eternally\n",
       "20                  in love there is                        love there                        love there\n",
       "21                 nomeasure of time                                of                                of\n",
       "22  they planned it all at the start  they planned it all at the start  they planned it all at the start\n",
       "23                     thatyou and i                               and                               and\n",
       "24        live in each other's heart         live in each others heart        live in each other's heart\n",
       "25              we maybe oceans away                      maybe oceans                      maybe oceans\n",
       "26                  you feel my love                      feel my love                      feel my love\n",
       "27               i hear what you say               i hear what you say               i hear what you say\n",
       "28            no truth is ever a lie             no truth is ever a li             no truth is ever a li\n",
       "29                i stumble and fall                    stumble and fa                    stumble and fa\n",
       "30             but i give you it all                       give you it                       give you it\n",
       "31              i am a woman in love              i am a woman in love              i am a woman in love\n",
       "32               and i'd do anything                 andid do anything               and i'd do anything\n",
       "33          to get you into my world          to get you into my world          to get you into my world\n",
       "34               and hold you within               and hold you within               and hold you within\n",
       "35              it's aright i defend                   aright i defend                   aright i defend\n",
       "36                 overand overagain                 overand overagain                 overand overagain\n",
       "37                      what do i do                              do i                              do i\n",
       "38              i am a woman in love                     am a woman in                     am a woman in\n",
       "39            and i'm talkin' to you                     talkin to you                    talkin' to you"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option(\"display.max_rows\", None) \n",
    "pd.set_option(\"display.width\", 0)  \n",
    "df[['transcript_no_punct','words_no_time','transcript_words_restored']].head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0078b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is a collection of functions to further clean the dataset later\n",
    "\n",
    "# Check if a string contains non-English characters\n",
    "def is_non_english(line,freq_threshold=3.0, ratio_threshold=0.5):\n",
    "    # Returns True if line has characters outside basic English alphabet and punctuation\n",
    "    if bool(re.search(r\"[^a-zA-Z0-9\\s.,?!'\\\"-]\", line)):\n",
    "        return True\n",
    "    words = [word for word in line.split()]\n",
    "    if not words:\n",
    "        return False  # Don't flag empty or punctuation-only lines\n",
    "\n",
    "    englishish = [zipf_frequency(word, 'en') >= freq_threshold for word in words]\n",
    "    english_ratio = sum(englishish) / len(englishish)\n",
    "\n",
    "    return english_ratio < ratio_threshold\n",
    "\n",
    "# Check if a string contains the same character 3 or more times in a row\n",
    "def three_or_more_repeats(text):\n",
    "    return bool(re.search(r\"(.)\\1{2,}\", text))\n",
    "\n",
    "# Collapse 3+ letters to 2\n",
    "def collapse_repeats(text):\n",
    "    return re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "\n",
    "# Further collapse certain words from 1 repeat to 0 repeats\n",
    "def collapse_known_repeats(text):\n",
    "    known_patterns = {\"noo\", \"whoo\", \"ohh\", \"yess\", \"goo\", \"aah\", \"woahh\", \"laa\", \"poww\", \"hii\", \"heyy\", \"ayy\", \"okay\", \"byee\"}    \n",
    "    \n",
    "    def collapse(word):\n",
    "            if word in known_patterns:\n",
    "                # Collapse all double letters in the word down to one occurrence\n",
    "                word = re.sub(r'(.)\\1+', r'\\1', word)\n",
    "            return word\n",
    "\n",
    "    return ' '.join(collapse(word) for word in text.split())\n",
    "\n",
    "\n",
    "d = enchant.Dict(\"en_US\")\n",
    "spell = SpellChecker()\n",
    "\n",
    "def is_dictionary_word(word):\n",
    "    if word in {'a','i'}:\n",
    "        return True\n",
    "    if len(word)>1:\n",
    "        if d.check(word):\n",
    "            return True\n",
    "        # spell allows for \"words\" like \"ni\", \"th\", etc...\n",
    "        #if word in spell:\n",
    "            #return True\n",
    "    return False\n",
    "\n",
    "def is_name(word):\n",
    "    if (df_names['name'].str.lower() == word).any():\n",
    "        #print('is a name')\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# For a given nonword, break it into 2+ pieces to see if those pieces are words\n",
    "def split_and_check(word):\n",
    "    length = len(word)\n",
    "\n",
    "    for num_pieces in range(2, 6): # range(2, 4)\n",
    "        # Generate all possible split positions for num_pieces\n",
    "        for split_points in combinations(range(1, length), num_pieces - 1):\n",
    "            indices = (0,) + split_points + (length,)\n",
    "            pieces = [word[indices[i]:indices[i + 1]] for i in range(len(indices) - 1)]\n",
    "\n",
    "            if all(is_dictionary_word(piece) for piece in pieces):\n",
    "                if num_pieces >= 4:\n",
    "                    print('found a',num_pieces, 'parter:',word,pieces)\n",
    "                return pieces\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def maybe_is_a_word(word):\n",
    "    pass\n",
    "    # make use of zipf_frequency here\n",
    "\n",
    "# Used for output formatting\n",
    "def add_quotes(word):\n",
    "    return f'\"{word}\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77abbb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found more than one match for \"yay\" so no action taken.\n"
     ]
    }
   ],
   "source": [
    "# Correct misspellings based on spell checker and phonetics checker\n",
    "dmeta = fuzzy.DMetaphone()\n",
    "\n",
    "def correct_misspelling(misspelled_word):\n",
    "    goal_phonetics = dmeta(misspelled_word)\n",
    "    matches = []\n",
    "    for word in spell.candidates(misspelled_word):\n",
    "        if dmeta(word) == goal_phonetics:\n",
    "            matches.append(word)\n",
    "    if len(matches) == 0:\n",
    "        print(misspelled_word,\"is likely misspelled, but couldn't find a match!\")\n",
    "    if len(matches) == 1:\n",
    "        print(\"Found one match:\",add_quotes(misspelled_word),\"corrects to\",add_quotes(matches[0]))\n",
    "    if len(matches) > 1:\n",
    "        print(\"Found more than one match for\",add_quotes(misspelled_word),\"so no action taken.\")\n",
    "\n",
    "correct_misspelling(\"yay\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a10ce7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False False\n"
     ]
    }
   ],
   "source": [
    "# Perform all 3 word checks to see which the word passes\n",
    "word = 'll'\n",
    "print(d.check(word), word in spell, (df_names['name'].str.lower() == word).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea3e1f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Not found.\n"
     ]
    }
   ],
   "source": [
    "# Check if something is a name, and if so, find its index\n",
    "word = 'ant'\n",
    "print(is_name('ant'))\n",
    "\n",
    "matches = df_names['name'].str.lower() == word.lower()\n",
    "\n",
    "if matches.any():\n",
    "    index = matches.idxmax()  # Returns the first True index\n",
    "    print(f\"Found at index: {index}\")\n",
    "else:\n",
    "    print(\"Not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5590a47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jared\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the tokenizer\n",
    "model_name = \"openai/whisper-base\"\n",
    "language = \"english\" # Change to your dataset's language\n",
    "task = \"transcribe\" # Use \"translate\" if you're translating to English\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(model_name, language=language, task=task)\n",
    "tokenizer = processor.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a75f8077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does zipf_frequency do?\n",
    "zipf_frequency(\"im\", lang=\"en\")\n",
    "\n",
    "def is_known_word(word, threshold=4.0):\n",
    "    return zipf_frequency(word, 'en') >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43afff93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dy', 'ou']\n"
     ]
    }
   ],
   "source": [
    "# Test how a word is tokenized here\n",
    "word = 'dyou'\n",
    "tokens = tokenizer.tokenize(word)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc63b04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Test if things are words here\n",
    "word = \"darling\"\n",
    "print(is_dictionary_word(word))\n",
    "\n",
    "name = 'francisco'\n",
    "print(is_name(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a601ec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a 4 parter: endeavour ['en', 'de', 'av', 'our']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadadoo ['dada', 'dad', 'ad', 'oo']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadadoo ['dada', 'dad', 'ad', 'oo']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadadoo ['dada', 'dad', 'ad', 'oo']\n",
      "found a 4 parter: siberian ['sib', 'er', 'i', 'an']\n",
      "found a 5 parter: transiberian ['trans', 'ib', 'er', 'i', 'an']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadadoo ['dada', 'dad', 'ad', 'oo']\n",
      "found a 4 parter: dadadadada ['dad', 'ad', 'a', 'dada']\n",
      "found a 4 parter: dadadadadoo ['dada', 'dad', 'ad', 'oo']\n",
      "found a 5 parter: toobigforhisbed ['too', 'big', 'for', 'his', 'bed']\n",
      "found a 4 parter: oseraindrops ['os', 'er', 'ain', 'drops']\n",
      "found a 5 parter: evilohouhohuh ['evil', 'oho', 'uh', 'oh', 'uh']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: acchroches ['ac', 'ch', 'roc', 'hes']\n",
      "found a 4 parter: acchroches ['ac', 'ch', 'roc', 'hes']\n",
      "found a 4 parter: acchroches ['ac', 'ch', 'roc', 'hes']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: practised ['pr', 'act', 'is', 'ed']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: shamandalie ['sham', 'and', 'a', 'lie']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: itcomestothe ['it', 'comes', 'to', 'the']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 5 parter: tommermaend ['to', 'mm', 'er', 'ma', 'end']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 5 parter: neimanmarcus ['ne', 'i', 'man', 'marc', 'us']\n",
      "found a 4 parter: sonofagun ['so', 'no', 'fa', 'gun']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: cherches ['ch', 'er', 'ch', 'es']\n",
      "found a 4 parter: nuumbers ['nu', 'um', 'be', 'rs']\n",
      "found a 5 parter: ohohohohoh ['oh', 'oh', 'oh', 'oh', 'oh']\n",
      "found a 4 parter: panthalassa ['pant', 'ha', 'lass', 'a']\n",
      "found a 5 parter: nemitoonam ['ne', 'mi', 'to', 'on', 'am']\n",
      "found a 5 parter: divoonatam ['di', 'vo', 'on', 'a', 'tam']\n",
      "found a 5 parter: nemidooni ['ne', 'mi', 'do', 'on', 'i']\n",
      "found a 4 parter: millionaries ['million', 'ar', 'i', 'es']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 5 parter: shadowwheretruemeaninglies ['shadow', 'where', 'true', 'meaning', 'lies']\n",
      "found a 5 parter: bidilidibi ['bi', 'di', 'li', 'di', 'bi']\n",
      "found a 5 parter: budibupdibu ['bu', 'dib', 'up', 'di', 'bu']\n",
      "found a 4 parter: bubllbubu ['bub', 'll', 'bu', 'bu']\n",
      "found a 4 parter: momories ['mom', 'or', 'i', 'es']\n",
      "found a 4 parter: rumadaidai ['rum', 'ad', 'aid', 'ai']\n",
      "found a 4 parter: rumadaidai ['rum', 'ad', 'aid', 'ai']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: petridish ['pe', 'tr', 'i', 'dish']\n",
      "found a 4 parter: shackabadoo ['shack', 'a', 'bad', 'oo']\n",
      "found a 4 parter: atentionsee ['a', 'tent', 'ion', 'see']\n",
      "found a 5 parter: fahrenheit ['fa', 'hr', 'en', 'he', 'it']\n",
      "found a 5 parter: aprilsnow ['a', 'pr', 'i', 'ls', 'now']\n",
      "found a 4 parter: knowiwantit ['know', 'i', 'wan', 'tit']\n",
      "found a 4 parter: knowiwantit ['know', 'i', 'wan', 'tit']\n",
      "found a 4 parter: wanttofeelyou ['want', 'to', 'feel', 'you']\n",
      "found a 4 parter: needtohearyou ['need', 'to', 'hear', 'you']\n",
      "found a 4 parter: thatkeepsmetrusting ['that', 'keeps', 'me', 'trusting']\n",
      "found a 5 parter: andnotbemovedby ['and', 'not', 'be', 'moved', 'by']\n",
      "found a 4 parter: andyougiveme ['and', 'you', 'give', 'me']\n",
      "found a 4 parter: holdmeinyourhands ['hold', 'meiny', 'our', 'hands']\n",
      "found a 4 parter: youwon'tletme ['you', \"won't\", 'let', 'me']\n",
      "found a 5 parter: youtakemybreathaway ['you', 'take', 'my', 'breath', 'away']\n",
      "found a 4 parter: youtakemein ['you', 'take', 'me', 'in']\n",
      "found a 4 parter: lovethisstrongnever ['love', 'this', 'strong', 'never']\n",
      "found a 4 parter: lovethisstrongnever ['love', 'this', 'strong', 'never']\n",
      "found a 4 parter: gotmelongago ['got', 'me', 'long', 'ago']\n",
      "found a 4 parter: someonemis ['som', 'eon', 'em', 'is']\n",
      "found a 4 parter: toknowyouloved ['to', 'know', 'you', 'loved']\n",
      "found a 4 parter: someonemis ['som', 'eon', 'em', 'is']\n",
      "found a 4 parter: whatyoudoto ['what', 'yo', 'udo', 'to']\n",
      "found a 4 parter: deepandcryout ['deep', 'and', 'cry', 'out']\n",
      "found a 4 parter: someonemis ['som', 'eon', 'em', 'is']\n",
      "found a 4 parter: toknowyouloved ['to', 'know', 'you', 'loved']\n",
      "found a 4 parter: someonemis ['som', 'eon', 'em', 'is']\n",
      "found a 4 parter: todreamofyou ['to', 'dream', 'of', 'you']\n",
      "found a 4 parter: toknowyouloved ['to', 'know', 'you', 'loved']\n",
      "found a 4 parter: hummingbiird ['humming', 'bi', 'i', 'rd']\n",
      "found a 4 parter: cigarretes ['cig', 'arr', 'et', 'es']\n",
      "found a 5 parter: faithfaithfaithfaithfaith ['faith', 'faith', 'faith', 'faith', 'faith']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: staanding ['st', 'a', 'an', 'ding']\n",
      "found a 4 parter: cambodia ['cam', 'bod', 'i', 'a']\n",
      "found a 4 parter: cambodia ['cam', 'bod', 'i', 'a']\n",
      "found a 4 parter: desapeart ['de', 'sap', 'ea', 'rt']\n",
      "found a 4 parter: behindcloseddoorsthey ['behind', 'closed', 'doors', 'they']\n",
      "found a 4 parter: behindcloseddoorsthey ['behind', 'closed', 'doors', 'they']\n",
      "found a 4 parter: ohhtime ['oh', 'ht', 'i', 'me']\n",
      "found a 4 parter: novocaine ['no', 'voc', 'ai', 'ne']\n",
      "found a 4 parter: novocaine ['no', 'voc', 'ai', 'ne']\n",
      "found a 4 parter: abacinate ['ab', 'ac', 'in', 'ate']\n",
      "found a 4 parter: woahmona ['wo', 'ah', 'mon', 'a']\n",
      "found a 4 parter: practising ['pr', 'ac', 'ti', 'sing']\n",
      "found a 5 parter: obsoliation ['ob', 'so', 'li', 'at', 'ion']\n",
      "found a 5 parter: obsoliation ['ob', 'so', 'li', 'at', 'ion']\n",
      "found a 4 parter: umandela ['um', 'an', 'de', 'la']\n",
      "found a 4 parter: umandela ['um', 'an', 'de', 'la']\n",
      "found a 4 parter: umandela ['um', 'an', 'de', 'la']\n",
      "found a 4 parter: umandela ['um', 'an', 'de', 'la']\n",
      "found a 4 parter: umandela ['um', 'an', 'de', 'la']\n",
      "found a 4 parter: siyakhona ['si', 'yak', 'hon', 'a']\n",
      "found a 4 parter: siyakhona ['si', 'yak', 'hon', 'a']\n",
      "found a 4 parter: umandela ['um', 'an', 'de', 'la']\n",
      "found a 4 parter: umandela ['um', 'an', 'de', 'la']\n",
      "found a 4 parter: umandela ['um', 'an', 'de', 'la']\n",
      "found a 4 parter: umandela ['um', 'an', 'de', 'la']\n",
      "found a 4 parter: hadtotella ['had', 'to', 'tel', 'la']\n",
      "found a 4 parter: amancouldbe ['a', 'man', 'could', 'be']\n",
      "found a 4 parter: opression ['op', 're', 'ss', 'ion']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: minnesota ['min', 'ne', 'so', 'ta']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: elvistears ['el', 'vi', 'st', 'ears']\n",
      "found a 4 parter: elvistears ['el', 'vi', 'st', 'ears']\n",
      "found a 5 parter: jagermeister ['ja', 'ger', 'me', 'i', 'ster']\n",
      "found a 4 parter: guardiaan ['guar', 'di', 'a', 'an']\n",
      "found a 4 parter: guardiaan ['guar', 'di', 'a', 'an']\n",
      "found a 4 parter: unmanageables ['unman', 'age', 'abl', 'es']\n",
      "found a 4 parter: guardiaan ['guar', 'di', 'a', 'an']\n",
      "found a 5 parter: halalalalalala ['halal', 'al', 'al', 'al', 'ala']\n",
      "found a 5 parter: halalalalalala ['halal', 'al', 'al', 'al', 'ala']\n",
      "found a 5 parter: halalalalalala ['halal', 'al', 'al', 'al', 'ala']\n",
      "found a 5 parter: whennobodyelsecanhelp ['when', 'nobody', 'else', 'can', 'help']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 5 parter: mysterioous ['my', 'ster', 'i', 'oo', 'us']\n",
      "found a 4 parter: serengeti ['ser', 'en', 'get', 'i']\n",
      "found a 4 parter: illinois ['ill', 'i', 'no', 'is']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: bridren ['br', 'i', 'dr', 'en']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 5 parter: americana ['am', 'er', 'i', 'can', 'a']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 5 parter: philadelphia ['phi', 'la', 'del', 'phi', 'a']\n",
      "found a 5 parter: philadelphia ['phi', 'la', 'del', 'phi', 'a']\n",
      "found a 5 parter: philadelphia ['phi', 'la', 'del', 'phi', 'a']\n",
      "found a 5 parter: philadelphia ['phi', 'la', 'del', 'phi', 'a']\n",
      "found a 5 parter: shalalalala ['sh', 'al', 'al', 'al', 'ala']\n",
      "found a 5 parter: ameerica ['a', 'me', 'er', 'i', 'ca']\n",
      "found a 5 parter: shalalalala ['sh', 'al', 'al', 'al', 'ala']\n",
      "found a 5 parter: shalalalala ['sh', 'al', 'al', 'al', 'ala']\n",
      "found a 4 parter: willyoutieit ['will', 'you', 'tie', 'it']\n",
      "found a 4 parter: desolaation ['de', 'sola', 'at', 'ion']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 5 parter: aquarius ['a', 'qu', 'ar', 'i', 'us']\n",
      "found a 4 parter: ashidori ['as', 'hi', 'dor', 'i']\n",
      "found a 4 parter: isogaseta ['i', 'so', 'gas', 'eta']\n",
      "found a 5 parter: omoidashita ['om', 'oi', 'dash', 'i', 'ta']\n",
      "found a 4 parter: hajimarun ['haj', 'i', 'ma', 'run']\n",
      "found a 4 parter: ilovethepain ['i', 'love', 'the', 'pain']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 5 parter: ddanddara ['dd', 'an', 'dd', 'ar', 'a']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: shakalaka ['sh', 'aka', 'la', 'ka']\n",
      "found a 4 parter: dominatus ['do', 'min', 'at', 'us']\n",
      "found a 4 parter: thingsain'trightgirl ['things', \"ain't\", 'right', 'girl']\n",
      "found a 4 parter: earswon'tstopringing ['ears', \"won't\", 'stop', 'ringing']\n",
      "found a 4 parter: shania ['sh', 'an', 'i', 'a']\n",
      "found a 4 parter: dakishimete ['dak', 'is', 'hi', 'mete']\n",
      "found a 4 parter: dakishimete ['dak', 'is', 'hi', 'mete']\n",
      "found a 5 parter: tsutaetai ['ts', 'ut', 'a', 'et', 'ai']\n",
      "found a 4 parter: dracula ['dr', 'a', 'cu', 'la']\n",
      "found a 4 parter: sonofagun ['so', 'no', 'fa', 'gun']\n",
      "found a 4 parter: woahwoah ['wo', 'ah', 'wo', 'ah']\n",
      "found a 4 parter: dominicana ['do', 'mini', 'can', 'a']\n",
      "found a 4 parter: ferricadooza ['ferric', 'ado', 'oz', 'a']\n",
      "found a 4 parter: americans ['am', 'er', 'i', 'cans']\n",
      "found a 4 parter: americans ['am', 'er', 'i', 'cans']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: soterios ['so', 'ter', 'i', 'os']\n",
      "found a 4 parter: hypnotised ['hyp', 'not', 'is', 'ed']\n",
      "found a 4 parter: it'sbeenrumoredthat [\"it's\", 'been', 'rumored', 'that']\n",
      "found a 4 parter: mytearsdryon ['my', 'tears', 'dr', 'yon']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: cheshma ['ch', 'es', 'hm', 'a']\n",
      "found a 4 parter: hoovsies ['hoo', 'vs', 'i', 'es']\n",
      "found a 5 parter: mysterioous ['my', 'ster', 'i', 'oo', 'us']\n",
      "found a 4 parter: dedecateboy ['de', 'de', 'cate', 'boy']\n",
      "found a 4 parter: youshinethelight ['you', 'shine', 'the', 'light']\n",
      "found a 4 parter: youmakethewhole ['you', 'make', 'the', 'whole']\n",
      "found a 5 parter: thelightonhiddenparts ['the', 'light', 'on', 'hidden', 'parts']\n",
      "found a 4 parter: inthehystericalrealm ['in', 'the', 'hysterical', 'realm']\n",
      "found a 4 parter: stupide ['st', 'up', 'i', 'de']\n",
      "found a 4 parter: hahahahahaa ['hah', 'aha', 'hah', 'aa']\n",
      "found a 4 parter: hahahahahaa ['hah', 'aha', 'hah', 'aa']\n",
      "found a 4 parter: quelched ['qu', 'el', 'ch', 'ed']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: youterterit's ['you', 'ter', 'ter', \"it's\"]\n",
      "found a 4 parter: alrealaugh ['al', 're', 'a', 'laugh']\n",
      "found a 4 parter: that'snowaytago [\"that's\", 'noway', 'ta', 'go']\n",
      "found a 4 parter: understooding ['under', 'st', 'oo', 'ding']\n",
      "found a 4 parter: ledietal ['led', 'i', 'et', 'al']\n",
      "found a 4 parter: ledietal ['led', 'i', 'et', 'al']\n",
      "found a 5 parter: neimanmarcus ['ne', 'i', 'man', 'marc', 'us']\n",
      "found a 4 parter: balarama ['bal', 'a', 'ram', 'a']\n",
      "found a 5 parter: momomomomore ['mo', 'mo', 'mo', 'mo', 'more']\n",
      "found a 5 parter: momomomomore ['mo', 'mo', 'mo', 'mo', 'more']\n",
      "found a 4 parter: acrowdcouldever ['a', 'crowd', 'could', 'ever']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: itsthoughtslikethis ['its', 'thoughts', 'like', 'this']\n",
      "found a 4 parter: goohohoh ['go', 'oh', 'oh', 'oh']\n",
      "found a 4 parter: woahwoah ['wo', 'ah', 'wo', 'ah']\n",
      "found a 4 parter: woahwoah ['wo', 'ah', 'wo', 'ah']\n",
      "found a 4 parter: blackned ['bl', 'ac', 'kn', 'ed']\n",
      "found a 5 parter: someindonesian ['some', 'in', 'done', 'si', 'an']\n",
      "found a 5 parter: neimanmarcus ['ne', 'i', 'man', 'marc', 'us']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: woahohoh ['wo', 'ah', 'oh', 'oh']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: stiings ['st', 'i', 'in', 'gs']\n",
      "found a 4 parter: stiings ['st', 'i', 'in', 'gs']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: sonofagun ['so', 'no', 'fa', 'gun']\n",
      "found a 4 parter: explaiin ['ex', 'pl', 'ai', 'in']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: taipei ['ta', 'i', 'pe', 'i']\n",
      "found a 4 parter: memorised ['mem', 'or', 'is', 'ed']\n",
      "found a 4 parter: memorised ['mem', 'or', 'is', 'ed']\n",
      "found a 5 parter: thesewingsweremadeto ['these', 'wings', 'we', 'remade', 'to']\n",
      "found a 5 parter: thesewingsweremadeto ['these', 'wings', 'we', 'remade', 'to']\n",
      "found a 5 parter: thesewingsweremadeto ['these', 'wings', 'we', 'remade', 'to']\n",
      "found a 5 parter: thesewingsweremadeto ['these', 'wings', 'we', 'remade', 'to']\n",
      "found a 4 parter: thesewingsweremade ['these', 'wings', 'we', 'remade']\n",
      "found a 5 parter: thesewingsweremadeto ['these', 'wings', 'we', 'remade', 'to']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 5 parter: lalalalala ['la', 'la', 'la', 'la', 'la']\n",
      "found a 5 parter: lalalalala ['la', 'la', 'la', 'la', 'la']\n",
      "found a 5 parter: lalalalala ['la', 'la', 'la', 'la', 'la']\n",
      "found a 5 parter: lalalalala ['la', 'la', 'la', 'la', 'la']\n",
      "found a 5 parter: lalalalala ['la', 'la', 'la', 'la', 'la']\n",
      "found a 5 parter: lalalalala ['la', 'la', 'la', 'la', 'la']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: histeria ['hi', 'ster', 'i', 'a']\n",
      "found a 4 parter: ifisaidsome ['if', 'i', 'said', 'some']\n",
      "found a 4 parter: youdon'tknownot ['you', \"don't\", 'know', 'not']\n",
      "found a 5 parter: boutthedreamsihave ['bout', 'the', 'dream', 'si', 'have']\n",
      "found a 5 parter: iwillmakeyousleep ['i', 'will', 'make', 'you', 'sleep']\n",
      "found a 4 parter: youdon'tknownot ['you', \"don't\", 'know', 'not']\n",
      "found a 5 parter: youwillbethemis ['you', 'will', 'be', 'them', 'is']\n",
      "found a 4 parter: youwillbegi ['you', 'will', 'be', 'gi']\n",
      "found a 4 parter: ifisaidsome ['if', 'i', 'said', 'some']\n",
      "found a 5 parter: youwouldtakethosewords ['you', 'would', 'take', 'those', 'words']\n",
      "found a 5 parter: boutthedreamsihave ['bout', 'the', 'dream', 'si', 'have']\n",
      "found a 5 parter: boutthedreamsihave ['bout', 'the', 'dream', 'si', 'have']\n",
      "found a 5 parter: iwillmakeyousleep ['i', 'will', 'make', 'you', 'sleep']\n",
      "found a 5 parter: boutthedreamsihave ['bout', 'the', 'dream', 'si', 'have']\n",
      "found a 4 parter: bethlehem ['bet', 'hl', 'eh', 'em']\n",
      "found a 5 parter: bequickquickquickquick ['be', 'quick', 'quick', 'quick', 'quick']\n",
      "found a 5 parter: wohohohoho ['wo', 'ho', 'ho', 'ho', 'ho']\n",
      "found a 5 parter: wohohohoho ['wo', 'ho', 'ho', 'ho', 'ho']\n",
      "found a 4 parter: bethlehem ['bet', 'hl', 'eh', 'em']\n",
      "found a 4 parter: bethlehem ['bet', 'hl', 'eh', 'em']\n",
      "found a 5 parter: beththlehem ['bet', 'ht', 'hl', 'eh', 'em']\n",
      "found a 4 parter: bethlehem ['bet', 'hl', 'eh', 'em']\n",
      "found a 4 parter: bethlehem ['bet', 'hl', 'eh', 'em']\n",
      "found a 4 parter: bethlehem ['bet', 'hl', 'eh', 'em']\n",
      "found a 4 parter: bethlehem ['bet', 'hl', 'eh', 'em']\n",
      "found a 4 parter: choochoo ['ch', 'oo', 'ch', 'oo']\n",
      "found a 4 parter: goodbyeyeyeye ['goodby', 'eye', 'ye', 'ye']\n",
      "found a 5 parter: shenandoah ['sh', 'en', 'an', 'do', 'ah']\n",
      "found a 4 parter: chiquitita ['chi', 'quit', 'i', 'ta']\n",
      "found a 4 parter: chiquitita ['chi', 'quit', 'i', 'ta']\n",
      "found a 4 parter: chiquitita ['chi', 'quit', 'i', 'ta']\n",
      "found a 4 parter: chiquitita ['chi', 'quit', 'i', 'ta']\n",
      "found a 4 parter: chiquitita ['chi', 'quit', 'i', 'ta']\n",
      "found a 4 parter: chiquitita ['chi', 'quit', 'i', 'ta']\n",
      "found a 4 parter: moutains ['mo', 'ut', 'a', 'ins']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: memorised ['mem', 'or', 'is', 'ed']\n",
      "found a 4 parter: partisian ['par', 'ti', 'si', 'an']\n",
      "found a 4 parter: gravitats ['gr', 'a', 'vi', 'tats']\n",
      "found a 4 parter: lalalala ['la', 'la', 'la', 'la']\n",
      "found a 4 parter: bananular ['ban', 'a', 'nu', 'lar']\n",
      "found a 5 parter: boobadoobadoop ['boob', 'ado', 'ob', 'ado', 'op']\n",
      "found a 4 parter: bananular ['ban', 'a', 'nu', 'lar']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: taipei ['ta', 'i', 'pe', 'i']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: isawyouwalk ['i', 'saw', 'you', 'walk']\n",
      "found a 5 parter: makehermineallmine ['make', 'her', 'mine', 'all', 'mine']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 5 parter: youturnandwalka ['you', 'turn', 'and', 'walk', 'a']\n",
      "found a 5 parter: wheniwantosay ['when', 'i', 'wan', 'to', 'say']\n",
      "found a 4 parter: givemeyourword ['give', 'me', 'your', 'word']\n",
      "found a 5 parter: youturnandwalka ['you', 'turn', 'and', 'walk', 'a']\n",
      "found a 5 parter: wheniwantosay ['when', 'i', 'wan', 'to', 'say']\n",
      "found a 4 parter: givemeyourword ['give', 'me', 'your', 'word']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: you'llbemygirl [\"you'll\", 'be', 'my', 'girl']\n",
      "found a 4 parter: doncamatic ['don', 'ca', 'ma', 'tic']\n",
      "found a 5 parter: incapaciate ['in', 'cap', 'ac', 'i', 'ate']\n",
      "found a 4 parter: sensimilla ['sen', 'si', 'mil', 'la']\n",
      "found a 4 parter: shangri ['sh', 'an', 'gr', 'i']\n",
      "found a 4 parter: obliviion ['ob', 'li', 'vi', 'ion']\n",
      "found a 4 parter: dedededid ['de', 'de', 'de', 'did']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 4 parter: american ['am', 'er', 'i', 'can']\n",
      "found a 5 parter: sceneries ['sc', 'en', 'er', 'i', 'es']\n",
      "found a 5 parter: thatwhenyoufeelyou've ['that', 'when', 'you', 'feel', \"you've\"]\n",
      "found a 5 parter: ahahahahahahah ['ah', 'aha', 'hah', 'aha', 'hah']\n",
      "found a 5 parter: philadelphia ['phi', 'la', 'del', 'phi', 'a']\n",
      "found a 4 parter: papperlapap ['pap', 'per', 'la', 'pap']\n",
      "found a 4 parter: papperlapap ['pap', 'per', 'la', 'pap']\n",
      "found a 4 parter: hypnotised ['hyp', 'not', 'is', 'ed']\n",
      "found a 4 parter: choochoo ['ch', 'oo', 'ch', 'oo']\n",
      "found a 5 parter: nonononono ['no', 'no', 'no', 'no', 'no']\n",
      "found a 4 parter: nononono ['no', 'no', 'no', 'no']\n",
      "found a 5 parter: fahrenheit ['fa', 'hr', 'en', 'he', 'it']\n",
      "found a 5 parter: fahrenheit ['fa', 'hr', 'en', 'he', 'it']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: hawaiian ['haw', 'a', 'ii', 'an']\n",
      "found a 4 parter: beacusea ['be', 'a', 'cu', 'sea']\n"
     ]
    }
   ],
   "source": [
    "# count WER score of interest\n",
    "count=0\n",
    "# count the number of occurrences of 3+ consecutive letters\n",
    "transcript_count=0\n",
    "# count the number of non-English character occurences\n",
    "nonenglish_count=0\n",
    "\n",
    "for i in range(len(df.words)):  #len(df.words)\n",
    "\n",
    "    result = []\n",
    "    collapsed_transcript_list = []\n",
    "    split_transcript_list = []\n",
    "    tokenized_transcript = []\n",
    "    tokenized_result = []\n",
    "\n",
    "    # pull the original line transcript and get rid of junk repeat letters like woooooo\n",
    "    transcript = df.transcript_no_punct[i]\n",
    "    transcript = collapse_repeats(transcript)\n",
    "    transcript = collapse_known_repeats(transcript)\n",
    "\n",
    "    # collapse repeat letters in the transcript\n",
    "    transcript_list = transcript.split(\" \")\n",
    "    for word in transcript_list:\n",
    "        collapsed_transcript_list.append(collapse_repeats(word))\n",
    "\n",
    "    transcript_list = collapsed_transcript_list\n",
    "\n",
    "    # break up incorrect compound words in the transcript\n",
    "    for word in transcript_list:\n",
    "        if not is_dictionary_word(word):\n",
    "            if not is_name(word):\n",
    "                split_attempt = split_and_check(word)\n",
    "                if split_attempt is False:\n",
    "                    split_transcript_list.append(word)\n",
    "                else:\n",
    "                    #print('we found a split! originally:',word)\n",
    "                    split_transcript_list.append(\" \".join(split_attempt))\n",
    "\n",
    "    transcript_list = split_transcript_list\n",
    "\n",
    "    # tokenize the transcript\n",
    "    for word in transcript_list:\n",
    "        token = tokenizer.tokenize(word)\n",
    "        tokenized_transcript.append(token)\n",
    "\n",
    "    transcript = \" \".join(transcript_list)\n",
    "    # check if transcript contains non-English words and chars\n",
    "    status = is_non_english(transcript)\n",
    "    if status:\n",
    "        #print(transcript, df.filename[i])\n",
    "        nonenglish_count += status\n",
    "\n",
    "    # loop over words to append them one at a time to result\n",
    "    for obj in df.words[i]:                \n",
    "        result.append(obj['word'])\n",
    "        token = tokenizer.tokenize(obj['word'])\n",
    "        tokenized_result.append(token)\n",
    "    line = \" \".join(result)\n",
    "    \n",
    "    # compute WER to assess quality of each line\n",
    "    wer_score = jiwer.wer(line, transcript)\n",
    "    if wer_score>.1:\n",
    "        #print(line+',',transcript+',', wer_score)\n",
    "        count += 1\n",
    "\n",
    "    #if status:\n",
    "        #print(\"orig. concat:\",line+',',\"token concat:\", tokenized_result,transcript+',',\"token concat:\",tokenized_transcript, \"WER score:\", wer_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
