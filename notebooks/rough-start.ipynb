{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c559b678",
   "metadata": {},
   "source": [
    "Basic template for using untrained Whisper to detect singular curse words in a music track. Demucs is used to split the audio first then the vocals tracks is muted during the curse words. \n",
    "\n",
    "Needed packages:\n",
    "- Whisper (audio-to-text, incl. pytorch, torchaudio)\n",
    "- Demucs (vocals stem separation)\n",
    "- pandas\n",
    "- os (file path management)\n",
    "- ffmpeg (for mp3)\n",
    "- soundfile (for wav)\n",
    "- pydub (for editing audio files)\n",
    "- mutagen (for preserving metadata)\n",
    "\n",
    "Ideas for improvement:\n",
    "- Use a fine-tuned HuBERT model instead of Whisper. Train on DALI database (or similar ?) to produce better audio-to-text from the original files.\n",
    "- Train a separate model to process the transcribed lyrics and flag words/phrases as explicit. Can likely use a pre-trained BERT, e.g., Jigsaw Toxic Comment Classifier but this will need a lot of work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14df4a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Whisper medium.en on cuda...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Check for cuda/cpu\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#### Load the model. I've tired the following:\n",
    "\n",
    "# large-v3-turbo (seems to perform the best?)\n",
    "# large-v3\n",
    "# medium.en (english only)\n",
    "# large (needs 10GB of VRAM and takes FOREVER)\n",
    "whisper_type = \"medium.en\"\n",
    "\n",
    "print(f'Loading Whisper {whisper_type} on {device}...')\n",
    "model = whisper.load_model(whisper_type, device=device)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aced78",
   "metadata": {},
   "source": [
    "Get file location and audio path, split into vocals and instruments. Demucs does a bunch of things automatically perhaps we can investigate further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c55779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import demucs.separate\n",
    "import os\n",
    "\n",
    "# Audio file path\n",
    "song = 'acumen'\n",
    "audio_file = f\"music/{song}.mp3\"\n",
    "\n",
    "# Format file path\n",
    "notebook_dir = os.getcwd()\n",
    "full_audio_path = os.path.join(notebook_dir, audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "802afae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model is a bag of 4 models. You will see that many progress bars per track.\n",
      "Separated tracks will be stored in C:\\Users\\dacla\\Documents\\auto-censoring-local\\separated\\mdx_extra\n",
      "Separating track c:\\Users\\dacla\\Documents\\auto-censoring-local\\music\\acumen.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 297.0/297.0 [00:02<00:00, 103.91seconds/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 297.0/297.0 [00:03<00:00, 97.21seconds/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 297.0/297.0 [00:02<00:00, 106.44seconds/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 297.0/297.0 [00:02<00:00, 112.80seconds/s]\n"
     ]
    }
   ],
   "source": [
    "# Split the vocals with demucs\n",
    "demucs.separate.main([\"--two-stems\", \"vocals\", \"-n\", \"mdx_extra\", full_audio_path])\n",
    "\n",
    "# Comments:\n",
    "# Add \"--mp3\" command for output in mp3 format. But .wav is lossless and will probably (?) sound better\n",
    "# listening with headphones the audio processed with --mp3 sounded pretty weird\n",
    "# mdx_extra is just one of the models included in demucs. try other models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06484b1d",
   "metadata": {},
   "source": [
    "Process the audio with Whisper. \n",
    "\n",
    "(I'm getting Triton kernel issues when I run this. I don't know why, this is apparently a Windows problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "216e7635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing audio at c:\\Users\\dacla\\Documents\\auto-censoring-local\\separated/mdx_extra/acumen/vocals.wav...\n"
     ]
    }
   ],
   "source": [
    "# Paths for vocals and no_vocals stems\n",
    "vocals = f\"separated/mdx_extra/{song}/vocals.wav\"\n",
    "no_vocals = f\"separated/mdx_extra/{song}/no_vocals.wav\"\n",
    "\n",
    "vocals_path = os.path.join(notebook_dir, vocals)\n",
    "no_vocals_path = os.path.join(notebook_dir, no_vocals)\n",
    "\n",
    "### Apply the transcription with Whisper\n",
    "# word_timestamps=True for timestamp info\n",
    "\n",
    "# run Whisper on vocals track only\n",
    "print(f'Transcribing audio at {vocals_path}...')\n",
    "result = model.transcribe(vocals_path, word_timestamps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf11993",
   "metadata": {},
   "source": [
    "Here we consider the different words to look out for. I think this is the part that will need the most work in terms of NLP to figure out what to edit. Obvious bad words are easy, but there's context dependent things that will need a separate model to interpret\n",
    "\n",
    "There's also issues of knowing the probabilities of the outputs. I'm not sure how to access the 2nd or 3rd word that Whisper thinks a particular segment is, if the 2nd most-likely word is a curse word and the prob is close to the 1st this is probably worth editing. \n",
    "\n",
    "Another problem is that there are some curse words that are only offensive in pairs: e.g., \"god damn\" is not allowed but \"damn\" generally is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e7902f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Whisper can sometimes add bits of punctuation, we don't care about those\n",
    "def remove_punctuation(s):\n",
    "    s = re.sub(r'[^a-zA-Z0-9\\s]', '', s)\n",
    "    return s.lower()\n",
    "\n",
    "# Create dataframe from the transcribed lyrics\n",
    "all = []\n",
    "for segment in result[\"segments\"]:\n",
    "    for word_info in segment['words']:\n",
    "        word = word_info['word'].strip()\n",
    "        word = remove_punctuation(word)\n",
    "        \n",
    "        start_time = float(word_info['start'])\n",
    "        end_time = float(word_info['end'])\n",
    "        prob = word_info['probability']\n",
    "        \n",
    "        all.append([word, start_time, end_time, prob])\n",
    "\n",
    "# Create Dataframe\n",
    "columns = ['word', 'start', 'end', 'prob']\n",
    "df_all = pd.DataFrame(all, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96aa2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit for things to look for\n",
    "curses = {'fuck', 'shit', 'bitch', 'nigga', 'cock', 'faggot', 'cunt', 'pussy', 'dick'} #To name a few...?\n",
    "pattern = '|'.join(curses)\n",
    "\n",
    "# I noticed it can create duplicate entries for some reason, delete them then save the log to a .csv\n",
    "df_all = df_all.drop_duplicates()\n",
    "\n",
    "# Add a column which is boolean 1 for \"is curse\" and 0 for \"is not curse\"\n",
    "df_all['explicit'] = df_all['word'].str.contains(pattern, case=False, na=False, regex=True).astype(int)\n",
    "\n",
    "# Save the dataframe\n",
    "df_all.to_csv(f'logs/{song}-{whisper_type}-all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "563f1e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        word   start     end      prob  explicit\n",
      "179  bastard  128.22  128.78  0.865051         1\n",
      "183  bastard  129.30  129.30  0.798574         1\n",
      "187  bastard  134.14  134.14  0.726056         1\n",
      "192  bastard  140.20  140.26  0.928996         1\n",
      "198  bastard  144.94  145.72  0.991119         1\n",
      "204  bastard  150.88  151.04  0.935638         1\n",
      "221  bastard  166.86  168.32  0.000246         1\n",
      "225  bastard  170.34  171.18  0.631440         1\n",
      "229  bastard  173.30  173.64  0.772456         1\n",
      "233  bastard  176.00  176.00  0.805456         1\n",
      "237  bastard  178.50  180.02  0.818085         1\n",
      "241  bastard  181.06  181.94  0.000038         1\n",
      "262  bastard  215.90  216.84  0.807133         1\n",
      "267  bastard  221.94  222.58  0.997818         1\n",
      "272  bastard  227.18  227.98  0.804872         1\n",
      "278  bastard  232.88  233.24  0.995458         1\n",
      "289  fucking  266.94  267.22  0.777497         1\n"
     ]
    }
   ],
   "source": [
    "# Select only those words which are curse words\n",
    "df = df_all[df_all['explicit']==1]\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b1c25cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "therefore the keep the failures from me its like im a sass its for the better half the weaker just watching upon my shores and ive got a need to always kick em down me jack reaction got a mouth on me im sure to make enemies our best friends why am i stricken with a pair of these ribs like a voice in an all round trap i hear snap down with me i hear snap down with me got a knack for not letting all my loved ones down maybe i keep smokes coming back how can i expect to ever be loved when all i got to do is just to break his heart we have a thing to censor the pride inside taking shots for nothing better than art always have to have that last word no matter what is it in my blood to have to take you down me jack reaction got a mouth on me i hear snap down with me i hear snap down with me as i am just a bastard im just a bastard im just a bastard cause im just a bastard cause i am just a bastard cause i am just a bastard to find the way to my own to be a stupid slushy hag im just a bastard im just a bastard im just a bastard im just a bastard im just a bastard im just a bastard i hear snap down with me i hear snap down with me down with me as i am just a bastard as im just a bastard as im just a bastard as i am just a bastard florence great to be here oh my god thats a fucking chicken mouth\n"
     ]
    }
   ],
   "source": [
    "## Inspect the full lyrics\n",
    "full_text = \" \".join(df_all['word'].tolist())\n",
    "print(full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c655beb",
   "metadata": {},
   "source": [
    "This function does the actual editing. Using the curses identified in df, mute the *audio* track only at the specified times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76028ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydub does the audio effects\n",
    "from pydub import AudioSegment\n",
    "\n",
    "## Applies silecning to input_audio_path at given list of times \n",
    "def silence_audio_segment(input_audio_path, output_audio_path, times):\n",
    "    \n",
    "    print(f'Applying silencing edits to vocals: {input_audio_path}')\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(input_audio_path)\n",
    "    for (start_ms, end_ms) in times:\n",
    "        # Select times to reverse\n",
    "        before_segment = audio[:start_ms]\n",
    "\n",
    "        # -60dB to the audio effectively mutes it\n",
    "        target_segment = audio[start_ms:end_ms] - 60\n",
    "\n",
    "        after_segment = audio[end_ms:]\n",
    "\n",
    "        # Concatenate: this can be made faster, but it's not a priority\n",
    "        audio = before_segment + target_segment + after_segment\n",
    "\n",
    "    # Export the modified audio\n",
    "    print(f'Outputting edited vocals to {output_audio_path}')             \n",
    "    audio.export(output_audio_path, format='wav') \n",
    "    return\n",
    "\n",
    "# Combines two audio tracks via their paths (vocals and instruments for example)\n",
    "def combine_audio(path1, path2, outpath):\n",
    "    audio1 = AudioSegment.from_file(path1, format='wav')\n",
    "    audio2 = AudioSegment.from_file(path2, format='wav')\n",
    "\n",
    "    combined_audio = audio1.overlay(audio2)\n",
    "\n",
    "    # format='mp3' for mp3 files   \n",
    "    combined_audio.export(outpath, format=\"mp3\") \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a3422a",
   "metadata": {},
   "source": [
    "Mute the explicit content, then recombines the vocals and no_vocals tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b3aaa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying silencing edits to vocals: c:\\Users\\dacla\\Documents\\auto-censoring-local\\separated/mdx_extra/acumen/vocals.wav\n",
      "Outputting edited vocals to c:\\Users\\dacla\\Documents\\auto-censoring-local\\separated/mdx_extra/acumen/vocals.wav\n",
      "Combining the audio...\n",
      "Exported to c:\\Users\\dacla\\Documents\\auto-censoring-local\\music/acumen-medium.en-edit.mp3\n"
     ]
    }
   ],
   "source": [
    "## Maybe a bit inefficient\n",
    "times = []\n",
    "for row in df.itertuples():\n",
    "    #word = row[1]\n",
    "    start = int(row[2]*1000)\n",
    "    end = int(row[3]*1000)\n",
    "\n",
    "    times.append((start, end))\n",
    "\n",
    "# Run the silencing script\n",
    "silence_audio_segment(vocals_path, vocals_path, times)\n",
    "\n",
    "## Output file name\n",
    "output_file = f\"music/{song}-{whisper_type}-edit.mp3\"\n",
    "output_path = os.path.join(notebook_dir, output_file)\n",
    "\n",
    "print('Combining the audio...')\n",
    "combine_audio(vocals_path, no_vocals_path, output_path)\n",
    "\n",
    "print(f'Exported to {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0d57bd",
   "metadata": {},
   "source": [
    "Last step is to transfer the metadata from the original track to the edited track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f1cd156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mutagen.easyid3 import EasyID3\n",
    "\n",
    "# Transfer the metadata from the original to the edited track\n",
    "def transfer_metadata(original_audio_path, edited_audio_path):\n",
    "    \n",
    "    audio_orig = EasyID3(original_audio_path)\n",
    "    audio_edit = EasyID3(edited_audio_path)\n",
    "\n",
    "    metadata = dict()\n",
    "\n",
    "    ## Add more if wanted\n",
    "    metadata['title'] = audio_orig.get('title', [None])[0]\n",
    "    metadata['artist'] = audio_orig.get('artist', [None])[0]\n",
    "    metadata['album'] = audio_orig.get('album', [None])[0]\n",
    "    metadata['date'] = audio_orig.get('date', [None])[0] # Often 'year' or full date\n",
    "    metadata['tracknumber'] = audio_orig.get('tracknumber', [None])[0]\n",
    "    \n",
    "    # Apply metadata to edited track\n",
    "    for key, value in metadata.items():\n",
    "        audio_edit[key] = [str(value)]\n",
    "\n",
    "    # and save\n",
    "    audio_edit.save()\n",
    "    return\n",
    "        \n",
    "transfer_metadata(original_audio_path=full_audio_path,\n",
    "                  edited_audio_path=output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
